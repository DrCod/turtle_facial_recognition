{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eX5VkLN0tzXY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eX5VkLN0tzXY",
    "outputId": "402e023b-f260-4466-f743-2528f2b299a1"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/adnan119/TRACER.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z7oCiQ0PtzSg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7oCiQ0PtzSg",
    "outputId": "462a23bf-7f07-4e13-e64c-98cef245e9e4"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/Karel911/TRACER/releases/download/v1.0/TRACER-Efficient-7.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Tb1SHT4mtzJO",
   "metadata": {
    "id": "Tb1SHT4mtzJO"
   },
   "outputs": [],
   "source": [
    "!mv ./TRACER-Efficient-7.pth ./best_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debf0186",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "debf0186",
    "outputId": "5ae55dbd-8185-4aeb-a224-710db427662a"
   },
   "outputs": [],
   "source": [
    "!pip install timm faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gqpE93Rxmw_W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqpE93Rxmw_W",
    "outputId": "77d763a0-4e01-4352-cb7b-4c7436d68168"
   },
   "outputs": [],
   "source": [
    "!pip install fastai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pSVrIaYF7nP-",
   "metadata": {
    "id": "pSVrIaYF7nP-"
   },
   "outputs": [],
   "source": [
    "!pip uninstall torch -y\n",
    "# CUDA 10.1\n",
    "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install fastai==2.0.19\n",
    "!pip install fastcore==1.3.1 \n",
    "!pip install wwf -q --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xQx-TMm-uGJJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQx-TMm-uGJJ",
    "outputId": "e5e954ca-e4ca-4d52-8610-abce8687c6fb"
   },
   "outputs": [],
   "source": [
    "%cd ./TRACER\n",
    "!mkdir ./results/\n",
    "!mkdir ./results/DUTS/\n",
    "!mkdir ./results/DUTS/TE7_0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eenzoybWuKrV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eenzoybWuKrV",
    "outputId": "6d5f3111-7ce9-4716-cd60-f2ce49381286"
   },
   "outputs": [],
   "source": [
    "!mv ../best_model.pth ./results/DUTS/TE7_0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lkPJpUDL4ZzT",
   "metadata": {
    "id": "lkPJpUDL4ZzT"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496611e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB : Restart notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de59e3",
   "metadata": {
    "id": "33de59e3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.learner import _update_first_layer\n",
    "import faiss\n",
    "from timm import create_model\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dHORnGuKnN",
   "metadata": {
    "id": "c7dHORnGuKnN"
   },
   "outputs": [],
   "source": [
    "# segment test images \n",
    "!python main.py test --exp_num 0 --arch 7 --img_size 640 --batch_size 16 --dataset \"DUTS\" --save_map True --data_path /content/turtle_recall/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DvgfeIJLuKjt",
   "metadata": {
    "id": "DvgfeIJLuKjt"
   },
   "outputs": [],
   "source": [
    "!ls seg_img | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N3LA8POgQ_JQ",
   "metadata": {
    "id": "N3LA8POgQ_JQ"
   },
   "outputs": [],
   "source": [
    "shutil.make_archive('./seg_img', 'zip', './seg_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94X93mdtXP2D",
   "metadata": {
    "id": "94X93mdtXP2D"
   },
   "outputs": [],
   "source": [
    "!mv /content/TRACER/seg_img.zip /content/drive/MyDrive/TurtleChallenge/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P9VEhbSkXfkH",
   "metadata": {
    "id": "P9VEhbSkXfkH"
   },
   "outputs": [],
   "source": [
    "!rm -r seg_img\n",
    "!rm seg_img.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seMrdMcWlnqo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seMrdMcWlnqo",
    "outputId": "9e0e7c8a-65df-4091-e69e-b74be7827c40"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YmNzedK3bL0r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmNzedK3bL0r",
    "outputId": "f707dedf-0d85-4336-a83f-3f9670e8bb03"
   },
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g9v0zY11pRrW",
   "metadata": {
    "id": "g9v0zY11pRrW"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SysveeFVZwQj",
   "metadata": {
    "id": "SysveeFVZwQj"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/TurtleChallenge/seg_img.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XKK1KCm0bfHe",
   "metadata": {
    "id": "XKK1KCm0bfHe"
   },
   "outputs": [],
   "source": [
    "!rm -r TRACER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sI3XPyOsZ3Ko",
   "metadata": {
    "id": "sI3XPyOsZ3Ko"
   },
   "outputs": [],
   "source": [
    "!unzip seg_img.zip -d clean_turtle_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hydg4HKVcPtO",
   "metadata": {
    "id": "Hydg4HKVcPtO"
   },
   "outputs": [],
   "source": [
    "!rm seg_img.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O18PaOeAm_HV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O18PaOeAm_HV",
    "outputId": "361c496a-d8d0-4c31-d66e-007dca7ad47a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "SOURCE_URL = 'https://storage.googleapis.com/dm-turtle-recall/images.tar'\n",
    "IMAGE_DIR = './turtle_recall/images'\n",
    "TAR_PATH = os.path.join(IMAGE_DIR, os.path.basename(SOURCE_URL))\n",
    "EXPECTED_IMAGE_COUNT = 13891\n",
    "\n",
    "%sx mkdir --parents \"{IMAGE_DIR}\"\n",
    "if len(os.listdir(IMAGE_DIR)) != EXPECTED_IMAGE_COUNT:\n",
    "  %sx wget --no-check-certificate -O \"{TAR_PATH}\" \"{SOURCE_URL}\"\n",
    "  %sx tar --extract --file=\"{TAR_PATH}\" --directory=\"{IMAGE_DIR}\"\n",
    "  %sx rm \"{TAR_PATH}\"\n",
    "\n",
    "print(f'The total number of images is: {len(os.listdir(IMAGE_DIR))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e4caf",
   "metadata": {
    "id": "961e4caf"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path(\".\")\n",
    "DATA_ROOT_DIR = Path(\"/content/turtle_recall/images\")\n",
    "# TRAIN_DIR = DATA_ROOT_DIR / \"train_clean_back\"\n",
    "# TEST_DIR = DATA_ROOT_DIR / \"test_clean_back\"\n",
    "# EXTRA_TRAIN_DIR= DATA_ROOT_DIR / \"extra_clean_back\"\n",
    "SUBMISSION_CSV_PATH = OUTPUT_DIR / \"submission.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c97aec",
   "metadata": {
    "id": "e4c97aec"
   },
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wb3WHGWXnpw0",
   "metadata": {
    "id": "Wb3WHGWXnpw0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import urllib.parse\n",
    "\n",
    "BASE_URL = 'https://storage.googleapis.com/dm-turtle-recall/'\n",
    "\n",
    "\n",
    "def read_csv_from_web(file_name):\n",
    "  url = urllib.parse.urljoin(BASE_URL, file_name)\n",
    "  content = requests.get(url).content\n",
    "  return pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
    "\n",
    "\n",
    "# Read in csv files.\n",
    "train = read_csv_from_web('train.csv')\n",
    "extra_train = read_csv_from_web('extra_images.csv')\n",
    "test_df = read_csv_from_web('test.csv')\n",
    "sample_submission = read_csv_from_web('sample_submission.csv')\n",
    "\n",
    "# Convert image_location strings to lowercase.\n",
    "for df in [train, test_df]:\n",
    "  df.image_location = df.image_location.apply(lambda x: x.lower())\n",
    "  assert set(df.image_location.unique()) == set(['left', 'right', 'top'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WZ_i1Eb6_j-u",
   "metadata": {
    "id": "WZ_i1Eb6_j-u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4IToLkrcnDSe",
   "metadata": {
    "id": "4IToLkrcnDSe"
   },
   "outputs": [],
   "source": [
    "# Custom metric for mapk:\n",
    "def mapk(preds, targets, k=5):\n",
    "  import torch\n",
    "  scores = []\n",
    "  for i, actual in enumerate(targets):\n",
    "    predicted = torch.topk(preds[i], k).indices\n",
    "\n",
    "    # APK\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for j, p in enumerate(predicted):\n",
    "      if p == actual and p not in predicted[:j]:\n",
    "        num_hits += 1.0\n",
    "        score += num_hits / (j + 1.0)\n",
    "\n",
    "    scores.append(score)\n",
    "\n",
    "  \n",
    "  return np.mean(scores) #MAPK\n",
    "\n",
    "# Create the model\n",
    "# learn = cnn_learner(dls, resnet50, metrics=[error_rate, mapk])\n",
    "\n",
    "# Run lr_find to pick a good learning rate\n",
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prKOCgvSnt6Y",
   "metadata": {
    "id": "prKOCgvSnt6Y"
   },
   "outputs": [],
   "source": [
    "classes = list(train.turtle_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0uIimn-Ko1vA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0uIimn-Ko1vA",
    "outputId": "e161e10d-2982-4cf2-df51-5e1814e20e19"
   },
   "outputs": [],
   "source": [
    "classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RyI17cRwOVBX",
   "metadata": {
    "id": "RyI17cRwOVBX"
   },
   "outputs": [],
   "source": [
    "new_data = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qtXIzmV4H4WP",
   "metadata": {
    "id": "qtXIzmV4H4WP"
   },
   "outputs": [],
   "source": [
    "new_data['image_id'] = new_data['image_id'] + '.png'\n",
    "new_data['image_path'] = new_data['image_id'].apply(lambda x : f'/content/clean_turtle_back/{str(x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kHawoBmaOq-8",
   "metadata": {
    "id": "kHawoBmaOq-8"
   },
   "outputs": [],
   "source": [
    "train['image_id']   = train['image_id'] + '.JPG'\n",
    "test_df['image_id'] = test_df['image_id'] + '.JPG'\n",
    "\n",
    "train['image_path']   = train['image_id'].apply(lambda x : DATA_ROOT_DIR / str(x))\n",
    "test_df['image_path'] = test_df['image_id'].apply(lambda x : DATA_ROOT_DIR / str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c32234",
   "metadata": {
    "id": "e9c32234"
   },
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6pzPrhqpjUj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "a6pzPrhqpjUj",
    "outputId": "472818bd-3348-4cfa-f11b-96e828b707b8"
   },
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ls6ebGfC2fj-",
   "metadata": {
    "id": "Ls6ebGfC2fj-"
   },
   "outputs": [],
   "source": [
    "folds = pd.concat([train, new_data], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e3375",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fb6e3375",
    "outputId": "a4f2f7e5-79ec-4ce4-b3c1-d53e27ed9f74"
   },
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(folds['turtle_id'])\n",
    "\n",
    "folds[\"label\"] = encoder.transform(folds['turtle_id'])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "for fold, (_, val_) in enumerate(skf.split(X=folds, y=folds.turtle_id)):\n",
    "    folds.loc[val_, \"kfold\"] = int(fold)\n",
    "    \n",
    "folds.drop('label',axis=1,inplace=True)\n",
    "folds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1de407",
   "metadata": {
    "id": "2c1de407"
   },
   "outputs": [],
   "source": [
    "folds['kfold'] = folds['kfold'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GH7BoTrLpv2y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "GH7BoTrLpv2y",
    "outputId": "c9962dc3-7bad-41dd-960b-f7117b7beebb"
   },
   "outputs": [],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f053efd3",
   "metadata": {
    "id": "f053efd3"
   },
   "outputs": [],
   "source": [
    "seed=42\n",
    "set_seed(seed, reproducible=True)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w97lBa3ProAu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w97lBa3ProAu",
    "outputId": "0474cf4c-83a0-467e-b998-c395dbc58ef9"
   },
   "outputs": [],
   "source": [
    "!ls /content/turtle_recall/images | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DGTAB4-aqM3A",
   "metadata": {
    "id": "DGTAB4-aqM3A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G6v0T1Y-IN7T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "G6v0T1Y-IN7T",
    "outputId": "f3d92359-2895-497e-a209-3128c1d16af9"
   },
   "outputs": [],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TA8N_PdNqzMl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "TA8N_PdNqzMl",
    "outputId": "851b20a1-5195-487a-fb92-a2da5c85c7be"
   },
   "outputs": [],
   "source": [
    "# folds['image_id'] = folds['image_id'] + '.png'\n",
    "# folds\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QHWh8Va-Gg5o",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "QHWh8Va-Gg5o",
    "outputId": "09206be5-257b-4246-f78e-84de09f68d3a"
   },
   "outputs": [],
   "source": [
    "extra_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HDyEqjMPWKwn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "HDyEqjMPWKwn",
    "outputId": "c650bb43-d86b-45da-9fa2-c200f89a7ec5"
   },
   "outputs": [],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5bcbad",
   "metadata": {
    "id": "6b5bcbad"
   },
   "source": [
    "# Creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae873768",
   "metadata": {
    "id": "ae873768"
   },
   "outputs": [],
   "source": [
    "Val_Fold = 0\n",
    "\n",
    "def get_x(r): return r['image_path']\n",
    "def get_y(r): return [r['turtle_id']]\n",
    "\n",
    "def splitter(df): \n",
    "\n",
    "  train_ = df.index[df.kfold != Val_Fold].tolist()\n",
    "\n",
    "  valid_ = df.index[df.kfold == Val_Fold].tolist()\n",
    "\n",
    "  return [train_,valid_]\n",
    "\n",
    "def create_dls(df=folds, bs=8,Val_Fold=0,Image_size=384): # b5_ns 512 \n",
    "    dblock = DataBlock(blocks = (ImageBlock,MultiCategoryBlock(vocab=classes)),\n",
    "                       get_x = get_x,\n",
    "                       get_y = get_y ,\n",
    "                       splitter = splitter,\n",
    "                       #item_tfms = [Resize(Image_size,method=ResizeMethod.Squish)],\n",
    "                       item_tfms = [Resize(768)], # b5_ns 1024\n",
    "                       batch_tfms =[*aug_transforms(size=Image_size, \n",
    "                                                    # do_flip=True, flip_vert=True, max_rotate=5.0, \n",
    "                                                    # p_affine=0.5, p_lighting=0.5, max_zoom=1.08,\n",
    "                                                    # max_lighting=0.2, max_warp=0.2\n",
    "                                                    ),\n",
    "                                     Normalize.from_stats(*imagenet_stats)]\n",
    "                      )\n",
    "\n",
    "    dls = dblock.dataloaders(folds,bs=bs)\n",
    "\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5f81c",
   "metadata": {
    "id": "86f5f81c"
   },
   "outputs": [],
   "source": [
    "dls = create_dls(df=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a97130c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "6a97130c",
    "outputId": "f454ba85-c85f-402e-cad7-2030aa76d9d9"
   },
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23adb8d2",
   "metadata": {
    "id": "23adb8d2"
   },
   "outputs": [],
   "source": [
    "target_map = {N:CLASS for N,CLASS in enumerate(dls.vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c375c4",
   "metadata": {
    "id": "d9c375c4"
   },
   "source": [
    "# Arc Face loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba681d",
   "metadata": {
    "id": "cfba681d"
   },
   "outputs": [],
   "source": [
    "# From https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/blob/master/src/modeling/metric_learning.py\n",
    "# Added type annotations, device, and 16bit support\n",
    "class ArcMarginLoss(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        s: float,\n",
    "        m: float,\n",
    "        easy_margin: bool,\n",
    "        ls_eps: float,\n",
    "    ):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, logits, targ):\n",
    "        cosine = F.linear(F.normalize(logits), F.normalize(self.weight))\n",
    "        # Enable 16 bit precision\n",
    "        cosine = cosine.to(torch.float32)\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        if self.ls_eps > 0:\n",
    "            targ = (1 - self.ls_eps) * targ + self.ls_eps / self.out_features\n",
    "        output = (targ * phi) + ((1.0 - targ) * cosine)\n",
    "        output *= self.s\n",
    "        loss =  F.cross_entropy(output, torch.argmax(targ, dim=1))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1gxi5CPqXm8",
   "metadata": {
    "id": "u1gxi5CPqXm8"
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, \n",
    "                 m=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        '''\n",
    "        in_features: dimension of the input\n",
    "        out_features: dimension of the last layer (in our case the classification)\n",
    "        s: norm of input feature\n",
    "        m: margin\n",
    "        ls_eps: label smoothing'''\n",
    "        \n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features, self.out_features = in_features, out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        # Fills the input `Tensor` with values according to the method described in\n",
    "        # `Understanding the difficulty of training deep feedforward neural networks`\n",
    "        # Glorot, X. & Bengio, Y. (2010)\n",
    "        # using a uniform distribution.\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m, self.sin_m = math.cos(m), math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------\n",
    "        one_hot = torch.zeros(cosine.size()).to('cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TiU5e38uIqj8",
   "metadata": {
    "id": "TiU5e38uIqj8"
   },
   "outputs": [],
   "source": [
    "# https://github.com/haqishen/Google-Landmark-Recognition-2020-3rd-Place-Solution/blob/main/landmark-recognition-2020-third-place-submission.ipynb\n",
    "import math\n",
    "\n",
    "class ArcMarginProduct_subcenter(nn.Module):\n",
    "    def __init__(self, in_features, out_features, k=3):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features*k, in_features))\n",
    "        self.reset_parameters()\n",
    "        self.k = k\n",
    "        self.out_features = out_features\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        cosine_all = F.linear(F.normalize(features), F.normalize(self.weight))\n",
    "        cosine_all = cosine_all.view(-1, self.out_features, self.k)\n",
    "        cosine, _ = torch.max(cosine_all, dim=2)\n",
    "        \n",
    "        return cosine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fM3pUSrTEZwl",
   "metadata": {
    "id": "fM3pUSrTEZwl"
   },
   "outputs": [],
   "source": [
    "# src: https://amaarora.github.io/2020/08/30/gempool.html\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        # Applies 2D average-pooling operation in kH * kW regions by step size\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcca16a",
   "metadata": {
    "id": "ffcca16a"
   },
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57418a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "7a57418a",
    "outputId": "1445665d-d7fd-4721-d215-f5b27fe8cd44"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "class building_model(Module):\n",
    "    def __init__(self,embedding_size:int,arch:str ='efficientnet_b0', pretrained:bool=True):\n",
    "        self.model = create_model(arch, pretrained=pretrained)\n",
    "        self.embedding = nn.Linear(self.model.get_classifier().in_features, embedding_size)\n",
    "        self.model.reset_classifier(num_classes=0, global_pool=\"avg\")\n",
    "    def forward(self,x):\n",
    "        features = self.model(x)\n",
    "        embeddings = self.embedding(features)\n",
    "        return embeddings\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725bc964",
   "metadata": {
    "id": "725bc964"
   },
   "outputs": [],
   "source": [
    "#emb_size = 512\n",
    "#model = building_model(emb_size,'efficientnet_b0',True)\n",
    "#model = nn.Sequential(*list(model.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a2955",
   "metadata": {
    "id": "734a2955"
   },
   "outputs": [],
   "source": [
    "def create_timm_body(arch:str, pretrained=True, drop_rate=0.0, cut=None, n_in=3):\n",
    "    \"Creates a body from any model in the `timm` library.\"\n",
    "    model = create_model(arch, pretrained=pretrained, drop_rate=drop_rate, \n",
    "                         num_classes=0, global_pool='')\n",
    "    _update_first_layer(model, n_in, pretrained)\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n",
    "    if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut): return cut(model)\n",
    "    else: raise NamedError(\"cut must be either integer or function\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6520a6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6520a6f",
    "outputId": "5d584907-b6d7-440e-9b89-ce726a568638"
   },
   "outputs": [],
   "source": [
    "emb_size = 512 # 2048 used b5_ns\n",
    "body = create_timm_body('tf_efficientnet_b7', pretrained=True)\n",
    "nf = num_features_model(nn.Sequential(*body.children()))\n",
    "head = nn.Sequential(GeM(),nn.Flatten(),\n",
    "                     nn.Linear(nf,emb_size,bias=False))\n",
    "\n",
    "model = nn.Sequential(body, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89861e70",
   "metadata": {
    "id": "89861e70"
   },
   "outputs": [],
   "source": [
    "# loss_func =  ArcFaceLoss()\n",
    "\n",
    "# loss_func = ArcMarginProduct_subcenter(in_features = emb_size, out_features=dls.c)\n",
    "\n",
    "loss_func = ArcMarginLoss(in_features=emb_size, out_features=dls.c,s=30.0,\n",
    "                          m = 0.3, easy_margin=False, ls_eps=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b4cd2",
   "metadata": {
    "id": "693b4cd2"
   },
   "outputs": [],
   "source": [
    "dls = create_dls(df=folds, bs=4,Image_size=512)\n",
    "learn = Learner(dls, model, \n",
    "                loss_func=loss_func, \n",
    "                # metrics = [accuracy_multi],\n",
    "                splitter=default_split\n",
    "                ).to_fp16()\n",
    "learn.freeze()\n",
    "\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf00cb71",
   "metadata": {
    "id": "cf00cb71"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def accuracy_multi(inp, targ, thresh=0.5, sigmoid=True):\n",
    "     \"Compute accuracy when `inp` and `targ` are the same size.\"\n",
    "     if sigmoid: inp = inp.sigmoid()\n",
    "     return ((inp>thresh)==targ.bool()).float().mean()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9f70e",
   "metadata": {
    "id": "4ec9f70e"
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5352b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "cce5352b",
    "outputId": "872f5e22-3a68-4e4e-86e3-7fe2e3b415ac"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1,lr_max=5e-4, wd = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0259b",
   "metadata": {
    "id": "d5a0259b"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(9,lr_max=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41e08a",
   "metadata": {
    "id": "7c41e08a"
   },
   "outputs": [],
   "source": [
    "learn.export('effnet_b7.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H---CdJgHyx7",
   "metadata": {
    "id": "H---CdJgHyx7"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y2GBLXmc_K7F",
   "metadata": {
    "id": "y2GBLXmc_K7F"
   },
   "outputs": [],
   "source": [
    "!cp effnet_b7.pkl /content/drive/MyDrive/TurtleChallenge/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c817e923",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c817e923",
    "outputId": "c7b4b5bc-c09d-4c30-d15a-889ff8b51c96"
   },
   "outputs": [],
   "source": [
    "del learn\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yvMH9pcx8QZM",
   "metadata": {
    "id": "yvMH9pcx8QZM"
   },
   "outputs": [],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uw9z1xx_u8D_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uw9z1xx_u8D_",
    "outputId": "056d2d1c-943f-442f-ec37-78f0ab272d08"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf028d",
   "metadata": {
    "id": "7cdf028d"
   },
   "outputs": [],
   "source": [
    "def load_eval_learner(learner_path,output_group,dls,device):\n",
    "    learn = load_learner(learner_path)\n",
    "    learn.model.to(device)\n",
    "    learn.dls = dls\n",
    "    hook = Hook(learn.model[output_group], lambda m,i,o: o)\n",
    "    return learn, hook\n",
    "\n",
    "def load_dataloaders(train_df,test_df,val_fold):\n",
    "\n",
    "  dls = create_dls(df=train_df, Image_size=384, bs=4, Val_Fold=val_fold) # b5_ns bs=8, image_size = 512\n",
    "\n",
    "  train_dataloader = dls.test_dl(train_df[train_df.kfold != val_fold],with_labels=True)\n",
    "  valid_dataloader = dls.test_dl(train_df[train_df.kfold == val_fold],with_labels=True)\n",
    "  test_dataloader  = dls.test_dl(test_df)\n",
    "  return train_dataloader, valid_dataloader, test_dataloader, dls\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_embeddings(module, dataloader, device, train=True):\n",
    "\n",
    "    all_image_names = []\n",
    "    all_embeddings = []\n",
    "    all_targets = []\n",
    "\n",
    "    if train:\n",
    "\n",
    "      for (x, y) in tqdm(dataloader):\n",
    "          images =  x.to(device)\n",
    "          targets = y.to(device)\n",
    "          embeddings = module.model(images)\n",
    "          all_embeddings.append(embeddings.cpu().numpy())\n",
    "          all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "\n",
    "      all_image_names = dataloader.items['image_id'].values\n",
    "      all_embeddings = np.vstack(all_embeddings)\n",
    "      all_targets = np.concatenate(all_targets)\n",
    "      all_targets = L(list(np.argmax(all_targets,axis=1)))\n",
    "      all_embeddings = normalize(all_embeddings, axis=1, norm=\"l2\")\n",
    "      all_targets = np.array(all_targets.map(target_map.__getitem__))\n",
    "      \n",
    "      return all_image_names, all_embeddings, all_targets\n",
    "    else:\n",
    "      for (x,) in tqdm(dataloader):\n",
    "          images =  x.to(device)\n",
    "          embeddings = module.model(images)\n",
    "          all_embeddings.append(embeddings.cpu().numpy())\n",
    "          \n",
    "      all_image_names = dataloader.items['image_id'].values\n",
    "      all_embeddings = np.vstack(all_embeddings)\n",
    "      all_embeddings = normalize(all_embeddings, axis=1, norm=\"l2\")\n",
    "      \n",
    "      return all_image_names, all_embeddings\n",
    "\n",
    "\n",
    "def create_and_search_index(embedding_size: int, train_embeddings: np.ndarray, val_embeddings: np.ndarray, k: int):\n",
    "    index = faiss.IndexFlatIP(embedding_size)\n",
    "    index.add(train_embeddings)\n",
    "    D, I = index.search(val_embeddings, k=k)  # noqa: E741\n",
    "\n",
    "    return D, I\n",
    "\n",
    "def create_val_targets_df(\n",
    "    train_targets: np.ndarray, val_image_names: np.ndarray, val_targets: np.ndarray\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    allowed_targets = classes\n",
    "    val_targets_df = pd.DataFrame(np.stack([val_image_names, val_targets], axis=1), columns=[\"image\", \"target\"])\n",
    "    val_targets_df.loc[~val_targets_df.target.isin(allowed_targets), \"target\"] = \"new_turtle\"\n",
    "\n",
    "    return val_targets_df\n",
    "\n",
    "def create_distances_df(\n",
    "    image_names: np.ndarray, targets: np.ndarray, D: np.ndarray, I: np.ndarray, stage: str  # noqa: E741\n",
    ") -> pd.DataFrame:\n",
    "    distances_df = []\n",
    "    for i, image_name in tqdm(enumerate(image_names), desc=f\"Creating {stage}_df\"):\n",
    "        target = targets[I[i]]\n",
    "        distances = D[i]\n",
    "        subset_preds = pd.DataFrame(np.stack([target, distances], axis=1), columns=[\"target\", \"distances\"])\n",
    "        subset_preds[\"image\"] = image_name\n",
    "        distances_df.append(subset_preds)\n",
    "    distances_df = pd.concat(distances_df).reset_index(drop=True)\n",
    "    distances_df = distances_df.groupby([\"image\", \"target\"]).distances.max().reset_index()\n",
    "    distances_df = distances_df.sort_values(\"distances\", ascending=False).reset_index(drop=True)\n",
    "    return distances_df\n",
    "\n",
    "def get_best_threshold(val_targets_df: pd.DataFrame, valid_df: pd.DataFrame):\n",
    "    best_th = 0\n",
    "    best_cv = 0\n",
    "    for th in [0.1 * x for x in range(11)]:\n",
    "        all_preds = get_predictions(valid_df, threshold=th)\n",
    "\n",
    "        cv = 0\n",
    "        for i, row in val_targets_df.iterrows():\n",
    "            target = row.target\n",
    "            preds = all_preds[row.image]\n",
    "            val_targets_df.loc[i, th] = map_per_image(target, preds)\n",
    "\n",
    "        cv = val_targets_df[th].mean()\n",
    "\n",
    "        print(f\"th={th} cv={cv}\")\n",
    "\n",
    "        if cv > best_cv:\n",
    "            best_th = th\n",
    "            best_cv = cv\n",
    "\n",
    "    print(f\"best_th={best_th}\")\n",
    "    print(f\"best_cv={best_cv}\")\n",
    "\n",
    "    # Adjustment: Since Public lb has nearly 10% 'new_individual' (Be Careful for private LB)\n",
    "    # val_targets_df[\"is_new_turtle\"] = val_targets_df.target == \"new_turtle\"\n",
    "    # val_scores = val_targets_df.groupby(\"is_new_turtle\").mean().T\n",
    "    # val_scores[\"adjusted_cv\"] = val_scores[True] * 0.1 + val_scores[False] * 0.9\n",
    "    # best_th = val_scores[\"adjusted_cv\"].idxmax()\n",
    "    # print(f\"best_th_adjusted={best_th}\")\n",
    "\n",
    "    return best_th, best_cv\n",
    "\n",
    "def get_predictions(df: pd.DataFrame, threshold: float = 0.2):\n",
    "    # sample_list = ['t_id_J5dngbNA', 't_id_OqU1NWEA', 't_id_p77GDtzg', 't_id_mXD9Bjsb','t_id_0DPPpRUz']\n",
    "\n",
    "    predictions = {}\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=f\"Creating predictions for threshold={threshold}\"):\n",
    "        if row.image in predictions:\n",
    "            if len(predictions[row.image]) == 5:\n",
    "                continue\n",
    "            predictions[row.image].append(row.target)\n",
    "        elif float(row.distances) > threshold:\n",
    "            predictions[row.image] = [row.target, \"new_turtle\"]\n",
    "        else:\n",
    "            predictions[row.image] = [\"new_turtle\", row.target]\n",
    "\n",
    "    for x in tqdm(predictions):\n",
    "        if len(predictions[x]) < 5:\n",
    "          # remaining = [y for y in sample_list if y not in predictions]\n",
    "          # predictions[x] = predictions[x]\n",
    "          # predictions[x] = predictions[x][:5]\n",
    "          predictions[x] = (predictions[x] + ['new_turtle']*5)[:5]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def map_per_image(label, predictions):\n",
    "    \"\"\"Computes the precision score of one image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label : string\n",
    "            The true label of the image\n",
    "    predictions : list\n",
    "            A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return 1 / (predictions[:5].index(label) + 1)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def create_predictions_df(test_df: pd.DataFrame, best_th: float) -> pd.DataFrame:\n",
    "    predictions = get_predictions(test_df, best_th)\n",
    "\n",
    "    predictions = pd.Series(predictions).reset_index()\n",
    "    predictions.columns = [\"image\", \"predictions\"]\n",
    "    predictions[\"predictions\"] = predictions[\"predictions\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29afe7f0",
   "metadata": {
    "id": "29afe7f0"
   },
   "outputs": [],
   "source": [
    "def infer(\n",
    "    model_path: str,\n",
    "    train_df: pd.DataFrame = folds,\n",
    "    test_df: pd.DataFrame = test_df,\n",
    "    val_fold: float = 0,\n",
    "    k: int = 50,\n",
    "    emb_size:int = emb_size\n",
    "):\n",
    "    train_dl, val_dl, test_dl,dls = load_dataloaders(folds,test_df,val_fold)\n",
    "    (learn, hook) = load_eval_learner(model_path,1,dls,torch.device(\"cuda\"))\n",
    "\n",
    "    train_image_names, train_embeddings, train_targets = get_embeddings(learn, train_dl,torch.device(\"cuda\"))\n",
    "    val_image_names, val_embeddings, val_targets = get_embeddings(learn, val_dl,torch.device(\"cuda\"))\n",
    "    test_image_names, test_embeddings = get_embeddings(learn, test_dl,torch.device(\"cuda\"),train=False)\n",
    "\n",
    "    D, I = create_and_search_index(emb_size, train_embeddings, val_embeddings, k)  # noqa: E741\n",
    "    print(\"Created index with train_embeddings\")\n",
    "    \n",
    "    val_targets_df = create_val_targets_df(train_targets, val_image_names, val_targets)\n",
    "    print(f\"val_targets_df=\\n{val_targets_df.head()}\")\n",
    "    print(f\"val_targets_df shape=\\n{val_targets_df.shape}\")\n",
    "    val_df = create_distances_df(val_image_names, train_targets, D, I, \"val\")\n",
    "    print(f\"val_df=\\n{val_df.head()}\")\n",
    "    print(f\"val_df shape=\\n{val_df.shape}\")\n",
    "    best_th, best_cv = get_best_threshold(val_targets_df, val_df)\n",
    "    print(f\"val_targets_df=\\n{val_targets_df.describe()}\")\n",
    "    print(f\"val_targets_df shape=\\n{val_targets_df.shape}\")\n",
    "    train_embeddings = np.concatenate([train_embeddings, val_embeddings])\n",
    "    train_targets = np.concatenate([train_targets, val_targets])\n",
    "    print(\"Updated train_embeddings and train_targets with val data\")\n",
    "\n",
    "    D, I = create_and_search_index(emb_size, train_embeddings, test_embeddings, k)  # noqa: E741\n",
    "    print(\"Created index with train_embeddings\")\n",
    "\n",
    "    test_df = create_distances_df(test_image_names, train_targets, D, I, \"test\")\n",
    "    print(f\"test_df=\\n{test_df.head()}\")\n",
    "    print(f\"test_df shape=\\n{test_df.shape}\")\n",
    "\n",
    "    predictions = create_predictions_df(test_df, best_th)\n",
    "    print(f\"predictions.head()={predictions.head()}\")\n",
    "    print(f\"predictions shape={predictions.shape}\")\n",
    " \n",
    "    # Fix missing predictions\n",
    "    # From https://www.kaggle.com/code/jpbremer/backfins-arcface-tpu-effnet/notebook\n",
    "    # public_predictions = pd.read_csv(PUBLIC_SUBMISSION_CSV_PATH)\n",
    "    # ids_without_backfin = np.load(IDS_WITHOUT_BACKFIN_PATH, allow_pickle=True)\n",
    "\n",
    "    # ids2 = public_predictions[\"image\"][~public_predictions[\"image\"].isin(predictions[\"image\"])]\n",
    "\n",
    "    # predictions = pd.concat(\n",
    "    #     [\n",
    "    #         predictions[~(predictions[\"image\"].isin(ids_without_backfin))],\n",
    "    #         public_predictions[public_predictions[\"image\"].isin(ids_without_backfin)],\n",
    "    #         public_predictions[public_predictions[\"image\"].isin(ids2)],\n",
    "    #     ]\n",
    "    # )\n",
    "    # predictions = predictions.drop_duplicates()\n",
    "\n",
    "    predictions.to_csv(f'submission_{val_fold}.csv', index=False)\n",
    "\n",
    "    print(f'Fold {val_fold} done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uoqpCn_IA648",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoqpCn_IA648",
    "outputId": "38aacb64-fc8a-44ca-f2ea-63d44c966d67"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/TurtleChallenge/models/effnet_b5_ns.pkl ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0p8PViE4ZZup",
   "metadata": {
    "id": "0p8PViE4ZZup"
   },
   "outputs": [],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OZ-tyexOHo3n",
   "metadata": {
    "id": "OZ-tyexOHo3n"
   },
   "outputs": [],
   "source": [
    "# test_data = test_df[test_df['image_location'] == 'right'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EWK6ltDpx557",
   "metadata": {
    "id": "EWK6ltDpx557"
   },
   "outputs": [],
   "source": [
    "# data = folds[folds['image_location'] == 'right'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44147ccf",
   "metadata": {
    "id": "44147ccf"
   },
   "outputs": [],
   "source": [
    "for fold_num in range(5):\n",
    "  \n",
    "  infer(train_df = folds, test_df = test_df, model_path=\"effnet_b5_ns.pkl\", val_fold=fold_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W1BZSCRkkrIo",
   "metadata": {
    "id": "W1BZSCRkkrIo"
   },
   "outputs": [],
   "source": [
    "sub_files = [\n",
    "                #  '/content/b5_ns_mixed_data__1_ (1).csv',\n",
    "                #  '/content/sub_ens_b6.csv',\n",
    "                #  '/content/sub_ens_3_ensemble_b6_b5_ns_b4.csv',\n",
    "                #  '/content/submission_5_folds_b4.csv',\n",
    "                #  '/content/submission_4.csv',\n",
    "                  '/content/final_blend.csv',\n",
    "                  '/content/sub_ens.csv',\n",
    "                  # '/content/sub_vit.csv',\n",
    "                  # '/content/orient_3_b4_ns_back.csv',\n",
    "                  # '/content/sub_ens_densenet2.csv',\n",
    "             \n",
    "\n",
    "]\n",
    "\n",
    "# Weights of the individual subs\n",
    "sub_weight = [\n",
    "                # 0.728**2,\n",
    "                # 0.689**2,\n",
    "                # 0.749**2,\n",
    "                # 0.712**2,\n",
    "                # 0.629**2,\n",
    "                # 0.770**2,\n",
    "                0.898**2,\n",
    "                0.897**2,\n",
    "                # 0.139**2\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hw1GX5YXoq_u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Hw1GX5YXoq_u",
    "outputId": "055334c3-bb5a-4b49-dc0d-febd81a31eac"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('/content/orient_3_b3_ns.csv')\n",
    "sub\n",
    "# sub['image_id'] = sub['image'].apply(lambda x: x.replace('.JPG', ''))\n",
    "# sub[['image_id', 'predictions']].to_csv('submission_0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lR85JT_fnXpR",
   "metadata": {
    "id": "lR85JT_fnXpR"
   },
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv('/content/final_blend.csv')\n",
    "sub1['predictions'] = sub1['prediction1'] + \" \" + sub1['prediction2']  + \" \" + sub1['prediction3'] + \" \" + sub1['prediction4'] + \" \" + sub1['prediction5']\n",
    "sub1['image'] = sub1['image_id']\n",
    "sub1[['image', 'predictions']].to_csv('/content/final_blend.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hVLh7btzpluz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "hVLh7btzpluz",
    "outputId": "d6a75a2c-5d1e-4113-d3e5-cc2b39b0bc55"
   },
   "outputs": [],
   "source": [
    "sub1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ls_TcYM7qIWi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Ls_TcYM7qIWi",
    "outputId": "3b188f7e-1a5a-4d69-e6ea-39aba8791f9d"
   },
   "outputs": [],
   "source": [
    "sub2 = pd.read_csv('/content/submit_1fold_dense.csv')\n",
    "sub2['predictions'] = sub2['prediction1'] + \" \" + sub2['prediction2']  + \" \" + sub2['prediction3'] + \" \" + sub2['prediction4'] + \" \" + sub2['prediction5']\n",
    "sub2['image'] = sub2['image_id']\n",
    "sub2[['image', 'predictions']].to_csv('submit_1fold_dense.csv', index=False)\n",
    "sub2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xItPKZoWkpF6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xItPKZoWkpF6",
    "outputId": "e46f0a71-4f78-4594-99c0-539d093bd9ac"
   },
   "outputs": [],
   "source": [
    "Hlabel = 'image' \n",
    "Htarget = 'predictions'\n",
    "npt = 5\n",
    "place_weights = {}\n",
    "for i in range(npt):\n",
    "    place_weights[i] = ( 1 / (i + 1) )\n",
    "    \n",
    "print(place_weights)\n",
    "\n",
    "lg = len(sub_files)\n",
    "sub = [None]*lg\n",
    "for i, file in enumerate( sub_files ):\n",
    "   \n",
    "    print(\"Reading {}: w={} - {}\". format(i, sub_weight[i], file))\n",
    "    reader = csv.DictReader(open(file,\"r\"))\n",
    "    sub[i] = sorted(reader, key=lambda d: str(d[Hlabel]))\n",
    "\n",
    "out = open(\"sub_ens.csv\", \"w\", newline='')\n",
    "writer = csv.writer(out)\n",
    "writer.writerow([Hlabel,Htarget])\n",
    "\n",
    "for p, row in enumerate(sub[0]):\n",
    "    target_weight = {}\n",
    "    for s in range(lg):\n",
    "        row1 = sub[s][p]\n",
    "        for ind, trgt in enumerate(row1[Htarget].split(' ')):\n",
    "            target_weight[trgt] = target_weight.get(trgt,0) + (place_weights[ind]*sub_weight[s])\n",
    "    tops_trgt = sorted(target_weight, key=target_weight.get, reverse=True)[:npt]\n",
    "    writer.writerow([row1[Hlabel], \" \".join(tops_trgt)])\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B5enG9PNDYx1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "B5enG9PNDYx1",
    "outputId": "d9dadb28-232c-42c1-9bb6-f829327416ec"
   },
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rFvhCXQvqvn-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "rFvhCXQvqvn-",
    "outputId": "caf41413-ccc2-404d-859a-31c0048c186e"
   },
   "outputs": [],
   "source": [
    "result = pd.read_csv('/content/sub_ens.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8z6Jr5hYrKEX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8z6Jr5hYrKEX",
    "outputId": "b31922dd-a23e-4ad0-b8b7-e92e13b734e4"
   },
   "outputs": [],
   "source": [
    "pred_list = result.predictions.apply(lambda x : x.split(\" \")).values.tolist()\n",
    "pred_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ydafVHlir6kQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ydafVHlir6kQ",
    "outputId": "98fc59dc-2a40-48bb-8776-0ac3ce1d9015"
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(pred_list, columns=['prediction1', 'prediction2', 'prediction3', 'prediction4', 'prediction5'])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0mGhe0usq_TF",
   "metadata": {
    "id": "0mGhe0usq_TF"
   },
   "outputs": [],
   "source": [
    "result_df['image_id'] = result['image'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wfyA5ce8rD5Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "wfyA5ce8rD5Q",
    "outputId": "6ace4850-58f0-4b06-bd1f-bf0322e8b680"
   },
   "outputs": [],
   "source": [
    "result_df['image_id'] = result_df['image_id'].apply(lambda x : x.replace('.JPG', ''))\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9Jxv1PnAszyq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "9Jxv1PnAszyq",
    "outputId": "4602f396-6eff-4b3d-eb03-77d71f89f315"
   },
   "outputs": [],
   "source": [
    "result_df = result_df[['image_id','prediction1',\t'prediction2','prediction3','prediction4','prediction5']].copy()\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kRUd9Mo-uuPm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRUd9Mo-uuPm",
    "outputId": "afee736a-d540-4dcf-db4b-ef84d23dfab4"
   },
   "outputs": [],
   "source": [
    "result_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tCKf1ouG1akZ",
   "metadata": {
    "id": "tCKf1ouG1akZ"
   },
   "outputs": [],
   "source": [
    "# result_df.fillna('new_turtle', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w4650OHe1pnl",
   "metadata": {
    "id": "w4650OHe1pnl"
   },
   "outputs": [],
   "source": [
    "result_df.to_csv('final_blend_7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X7dGTy6G-CyO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7dGTy6G-CyO",
    "outputId": "fcd3f7be-aca7-420b-faaa-8ce8e95fc24f"
   },
   "outputs": [],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j63tRijjM6nh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "j63tRijjM6nh",
    "outputId": "faf427be-7197-46b8-bca7-3ffd3da7a7c6"
   },
   "outputs": [],
   "source": [
    "final_sub = pd.concat([\n",
    "                      pd.read_csv('/content/sub_left.csv'),\n",
    "                      pd.read_csv('/content/sub_right.csv'),\n",
    "                      pd.read_csv('/content/sub_top.csv'), \n",
    "                      ], axis=0)\n",
    "final_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AOaWpRod7mIE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "AOaWpRod7mIE",
    "outputId": "b48cad9f-ed93-444c-896d-46ec4651aeaf"
   },
   "outputs": [],
   "source": [
    "final_sub['image_id'] = final_sub['image_id'].apply(lambda x : x.replace('.JPG',''))\n",
    "final_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "si6JAjr7NMDY",
   "metadata": {
    "id": "si6JAjr7NMDY"
   },
   "outputs": [],
   "source": [
    "final_sub.to_csv('orient_3_b4_ns_back.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1c6ded",
   "metadata": {
    "id": "1e1c6ded"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "bs = 32\n",
    "for Fold in range(N_SPLITS):\n",
    "    print(f'Epoch-{Fold}')\n",
    "    dls = create_dls(Val_Fold=Fold,bs=bs)\n",
    "    learn = cnn_learner(dls, resnet18, metrics=partial(accuracy_multi,thresh=0.2))\n",
    "    learn = learn.to_fp16()\n",
    "    learn.fit_one_cycle(1,lr_max=slice(2.2e-6, 2e-4))\n",
    "    learn.export(f'learn{Fold}.pkl')\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fastai-baseline-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14970.347666,
   "end_time": "2022-03-29T19:44:50.044679",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-29T15:35:19.697013",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
