{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations (timm + FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-27T13:10:59.441748Z",
     "iopub.status.busy": "2022-04-27T13:10:59.441379Z",
     "iopub.status.idle": "2022-04-27T13:11:27.279324Z",
     "shell.execute_reply": "2022-04-27T13:11:27.278458Z",
     "shell.execute_reply.started": "2022-04-27T13:10:59.441663Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q timm faiss-gpu\n",
    "!pip install -q Pillow==9.0.0\n",
    "!pip uninstall -y torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-27T13:11:27.281380Z",
     "iopub.status.busy": "2022-04-27T13:11:27.281151Z",
     "iopub.status.idle": "2022-04-27T13:11:36.823697Z",
     "shell.execute_reply": "2022-04-27T13:11:36.822945Z",
     "shell.execute_reply.started": "2022-04-27T13:11:27.281351Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Callable, Dict, Optional, Tuple\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from scipy import spatial\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "from albumentations.pytorch import transforms\n",
    "import albumentations as A\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from timm.optim import create_optimizer_v2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import normalize, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:11:36.827128Z",
     "iopub.status.busy": "2022-04-27T13:11:36.826927Z",
     "iopub.status.idle": "2022-04-27T13:13:40.539633Z",
     "shell.execute_reply": "2022-04-27T13:13:40.538527Z",
     "shell.execute_reply.started": "2022-04-27T13:11:36.827104Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title Download images\n",
    "import os\n",
    "SOURCE_URL = 'https://storage.googleapis.com/dm-turtle-recall/images.tar'\n",
    "IMAGE_DIR = './turtle_recall/images'\n",
    "TAR_PATH = os.path.join(IMAGE_DIR, os.path.basename(SOURCE_URL))\n",
    "EXPECTED_IMAGE_COUNT = 13891\n",
    "\n",
    "%sx mkdir --parents \"{IMAGE_DIR}\"\n",
    "if len(os.listdir(IMAGE_DIR)) != EXPECTED_IMAGE_COUNT:\n",
    "  %sx wget --no-check-certificate -O \"{TAR_PATH}\" \"{SOURCE_URL}\"\n",
    "  %sx tar --extract --file=\"{TAR_PATH}\" --directory=\"{IMAGE_DIR}\"\n",
    "  %sx rm \"{TAR_PATH}\"\n",
    "\n",
    "print(f'The total number of images is: {len(os.listdir(IMAGE_DIR))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:40.547841Z",
     "iopub.status.busy": "2022-04-27T13:13:40.545734Z",
     "iopub.status.idle": "2022-04-27T13:13:43.126378Z",
     "shell.execute_reply": "2022-04-27T13:13:43.125639Z",
     "shell.execute_reply.started": "2022-04-27T13:13:40.547801Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import urllib.parse\n",
    "\n",
    "BASE_URL = 'https://storage.googleapis.com/dm-turtle-recall/'\n",
    "\n",
    "N_SPLITS = 5\n",
    "\n",
    "def read_csv_from_web(file_name):\n",
    "    url = urllib.parse.urljoin(BASE_URL, file_name)\n",
    "    content = requests.get(url).content\n",
    "    return pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
    "\n",
    "\n",
    "# Read in csv files.\n",
    "train_df = read_csv_from_web('train.csv')\n",
    "extra_train = read_csv_from_web('extra_images.csv')\n",
    "test_df = read_csv_from_web('test.csv')\n",
    "sample_submission = read_csv_from_web('sample_submission.csv')\n",
    "\n",
    "# Convert image_location strings to lowercase.\n",
    "for df in [train_df, test_df]:\n",
    "    df.image_location = df.image_location.apply(lambda x: x.lower())\n",
    "    assert set(df.image_location.unique()) == set(['left', 'right', 'top'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:43.127818Z",
     "iopub.status.busy": "2022-04-27T13:13:43.127531Z",
     "iopub.status.idle": "2022-04-27T13:13:43.148957Z",
     "shell.execute_reply": "2022-04-27T13:13:43.148280Z",
     "shell.execute_reply.started": "2022-04-27T13:13:43.127781Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['image_id']   = train_df['image_id'] + '.JPG'\n",
    "test_df['image_id'] = test_df['image_id'] + '.JPG'\n",
    "extra_train['image_id'] = extra_train['image_id'] + '.JPG'\n",
    "\n",
    "train_df['image_path']   = train_df['image_id'].apply(lambda x : f'./turtle_recall/images/{str(x)}')\n",
    "test_df['image_path'] = test_df['image_id'].apply(lambda x : f'./turtle_recall/images/{str(x)}')\n",
    "extra_train['image_path'] = extra_train['image_id'].apply(lambda x : f'./turtle_recall/images/{str(x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:43.150406Z",
     "iopub.status.busy": "2022-04-27T13:13:43.150150Z",
     "iopub.status.idle": "2022-04-27T13:13:43.155883Z",
     "shell.execute_reply": "2022-04-27T13:13:43.154952Z",
     "shell.execute_reply.started": "2022-04-27T13:13:43.150371Z"
    }
   },
   "outputs": [],
   "source": [
    "extra_train['image_location'] = \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:43.157971Z",
     "iopub.status.busy": "2022-04-27T13:13:43.157642Z",
     "iopub.status.idle": "2022-04-27T13:13:43.197114Z",
     "shell.execute_reply": "2022-04-27T13:13:43.196455Z",
     "shell.execute_reply.started": "2022-04-27T13:13:43.157937Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, extra_train], axis=0, ignore_index=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:43.198667Z",
     "iopub.status.busy": "2022-04-27T13:13:43.198389Z",
     "iopub.status.idle": "2022-04-27T13:13:43.206384Z",
     "shell.execute_reply": "2022-04-27T13:13:43.205557Z",
     "shell.execute_reply.started": "2022-04-27T13:13:43.198632Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.turtle_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:43.208419Z",
     "iopub.status.busy": "2022-04-27T13:13:43.207983Z",
     "iopub.status.idle": "2022-04-27T13:13:43.218218Z",
     "shell.execute_reply": "2022-04-27T13:13:43.217436Z",
     "shell.execute_reply.started": "2022-04-27T13:13:43.208375Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['image_location'] = train_df['image_location'].map({'top':0, 'left':1, 'right':2, 'unknown' : 3})\n",
    "test_df['image_location'] = test_df['image_location'].map({'top':0, 'left':1, 'right':2, 'unknown': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:43.221920Z",
     "iopub.status.busy": "2022-04-27T13:13:43.221517Z",
     "iopub.status.idle": "2022-04-27T13:13:43.243899Z",
     "shell.execute_reply": "2022-04-27T13:13:43.243291Z",
     "shell.execute_reply.started": "2022-04-27T13:13:43.221887Z"
    }
   },
   "outputs": [],
   "source": [
    "label_counts = dict(train_df.turtle_id.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:43.245287Z",
     "iopub.status.busy": "2022-04-27T13:13:43.244984Z",
     "iopub.status.idle": "2022-04-27T13:13:43.257438Z",
     "shell.execute_reply": "2022-04-27T13:13:43.255636Z",
     "shell.execute_reply.started": "2022-04-27T13:13:43.245250Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:43.261253Z",
     "iopub.status.busy": "2022-04-27T13:13:43.261070Z",
     "iopub.status.idle": "2022-04-27T13:13:43.287963Z",
     "shell.execute_reply": "2022-04-27T13:13:43.287315Z",
     "shell.execute_reply.started": "2022-04-27T13:13:43.261230Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['label_count'] = [label_counts[x] for x in train_df.turtle_id]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:43.289505Z",
     "iopub.status.busy": "2022-04-27T13:13:43.289231Z",
     "iopub.status.idle": "2022-04-27T13:13:44.007661Z",
     "shell.execute_reply": "2022-04-27T13:13:44.006561Z",
     "shell.execute_reply.started": "2022-04-27T13:13:43.289456Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.label_count.min(), train_df.label_count.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.009681Z",
     "iopub.status.busy": "2022-04-27T13:13:44.009348Z",
     "iopub.status.idle": "2022-04-27T13:13:44.021281Z",
     "shell.execute_reply": "2022-04-27T13:13:44.020530Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.009642Z"
    }
   },
   "outputs": [],
   "source": [
    "extra_train.turtle_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.023003Z",
     "iopub.status.busy": "2022-04-27T13:13:44.022551Z",
     "iopub.status.idle": "2022-04-27T13:13:44.032274Z",
     "shell.execute_reply": "2022-04-27T13:13:44.031384Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.022963Z"
    }
   },
   "outputs": [],
   "source": [
    "extra_train.turtle_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.034202Z",
     "iopub.status.busy": "2022-04-27T13:13:44.033579Z",
     "iopub.status.idle": "2022-04-27T13:13:44.042596Z",
     "shell.execute_reply": "2022-04-27T13:13:44.041806Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.034164Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop classes with counts less than 10\n",
    "train_df = train_df[train_df['label_count'] > 10].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.044524Z",
     "iopub.status.busy": "2022-04-27T13:13:44.043713Z",
     "iopub.status.idle": "2022-04-27T13:13:44.055601Z",
     "shell.execute_reply": "2022-04-27T13:13:44.054953Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.044484Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.057464Z",
     "iopub.status.busy": "2022-04-27T13:13:44.057007Z",
     "iopub.status.idle": "2022-04-27T13:13:44.062763Z",
     "shell.execute_reply": "2022-04-27T13:13:44.062059Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.057428Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.064850Z",
     "iopub.status.busy": "2022-04-27T13:13:44.064225Z",
     "iopub.status.idle": "2022-04-27T13:13:44.122169Z",
     "shell.execute_reply": "2022-04-27T13:13:44.121476Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.064811Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "train_df[\"turtle_id\"] = encoder.fit_transform(train_df[\"turtle_id\"])\n",
    "np.save('turtle_ids.npy', encoder.classes_)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS)\n",
    "for fold, (_, val_) in enumerate(skf.split(X=train_df, y=train_df.turtle_id)):\n",
    "    train_df.loc[val_, \"kfold\"] = fold\n",
    "\n",
    "train_df = train_df.astype({'kfold': 'int8'})\n",
    "train_df.to_csv('./train_folds.csv', index=False)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.123907Z",
     "iopub.status.busy": "2022-04-27T13:13:44.123415Z",
     "iopub.status.idle": "2022-04-27T13:13:44.141064Z",
     "shell.execute_reply": "2022-04-27T13:13:44.140346Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.123867Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df[\"turtle_id\"] = 0\n",
    "test_df.to_csv('./test.csv', index=False)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.143339Z",
     "iopub.status.busy": "2022-04-27T13:13:44.142858Z",
     "iopub.status.idle": "2022-04-27T13:13:44.153507Z",
     "shell.execute_reply": "2022-04-27T13:13:44.152676Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.143298Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['image_name'] = train_df['image_id'].apply(lambda x : x.replace('.JPG', ''))\n",
    "test_df['image_name']  = test_df['image_id'].apply(lambda x : x.replace('.JPG', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.155404Z",
     "iopub.status.busy": "2022-04-27T13:13:44.154978Z",
     "iopub.status.idle": "2022-04-27T13:13:44.190307Z",
     "shell.execute_reply": "2022-04-27T13:13:44.189557Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.155363Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('./train_folds.csv', index=False)\n",
    "test_df.to_csv('./test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.191418Z",
     "iopub.status.busy": "2022-04-27T13:13:44.191222Z",
     "iopub.status.idle": "2022-04-27T13:13:44.210331Z",
     "shell.execute_reply": "2022-04-27T13:13:44.209588Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.191392Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.212088Z",
     "iopub.status.busy": "2022-04-27T13:13:44.211610Z",
     "iopub.status.idle": "2022-04-27T13:13:44.228336Z",
     "shell.execute_reply": "2022-04-27T13:13:44.227513Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.212045Z"
    }
   },
   "outputs": [],
   "source": [
    "class TurtleDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv, trainFlag):\n",
    "        '''Module to create the PyTorch Dataset.\n",
    "        csv: full dataframe (train or test)\n",
    "        trainFlag: True if csv is a training/validation dataset, False otherwise\n",
    "        return: image and class target if trainFlag, otherwise only image'''\n",
    "        \n",
    "        self.csv = csv\n",
    "        self.trainFlag = trainFlag\n",
    "        if self.trainFlag:\n",
    "            self.transform = A.Compose([\n",
    "                                        A.Affine(rotate=(-15, 15), translate_percent=(0.0, 0.25), \n",
    "                                                 shear=(-3, 3), p=0.5),\n",
    "                                        A.RandomResizedCrop(512, 512, scale=(0.9, 1.0),\n",
    "                                                            ratio=(0.75, 1.3333333333)),\n",
    "                                        A.ToGray(p=0.1),\n",
    "                                        A.GaussianBlur(blur_limit=(3, 7), p=0.05),\n",
    "                                        A.GaussNoise(p=0.05),\n",
    "                                        A.RandomGridShuffle(grid=(2, 2), p=0.3),\n",
    "                                        A.Posterize(p=0.2),\n",
    "                                        A.RandomBrightnessContrast(p=0.5),\n",
    "                                        A.Cutout(p=0.05),\n",
    "                                        A.RandomSnow(p=0.1),\n",
    "                                        A.RandomRain(p=0.05),\n",
    "                                        A.Normalize()\n",
    "\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = A.Compose([\n",
    "                A.RandomResizedCrop(512, 512),\n",
    "                A.Normalize()\n",
    "            ])\n",
    "\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get data\n",
    "        row = self.csv.iloc[index]\n",
    "        \n",
    "        # Read and transform the image\n",
    "        image = cv2.imread(row.image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        transformed_img = self.transform(image=image)['image'].astype(np.float32)\n",
    "        image = transformed_img.transpose(2, 0, 1)\n",
    "        image = torch.tensor(image)            \n",
    "        loc_target = torch.tensor(row.image_location)\n",
    "        \n",
    "        image_name = row.image_name\n",
    "\n",
    "        if self.trainFlag:\n",
    "            target = torch.tensor(row.turtle_id)\n",
    "            return {'image': image, 'image_name': image_name,'target': target, 'loc_target' : loc_target }\n",
    "        \n",
    "        else:\n",
    "            return {'image' :image,'image_name': image_name, 'loc_target':loc_target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.230091Z",
     "iopub.status.busy": "2022-04-27T13:13:44.229674Z",
     "iopub.status.idle": "2022-04-27T13:13:44.249297Z",
     "shell.execute_reply": "2022-04-27T13:13:44.248410Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.230051Z"
    }
   },
   "outputs": [],
   "source": [
    "class LitDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_csv_encoded_folded: str,\n",
    "        test_csv: str,\n",
    "        image_size: int,\n",
    "        batch_size: int,\n",
    "        num_workers: int,\n",
    "        val_split: float = 0.1,\n",
    "        val_fold: int = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.train_df = pd.read_csv(train_csv_encoded_folded)\n",
    "        self.test_df = pd.read_csv(test_csv)\n",
    "        \n",
    "        self.transform = create_transform(\n",
    "            input_size=(self.hparams.image_size, self.hparams.image_size),\n",
    "            crop_pct=1.0,\n",
    "        )\n",
    "        self.num_classes = len(set(\n",
    "            list(self.train_df[\"turtle_id\"].values) + list(self.test_df[\"turtle_id\"].values)\n",
    "        ))\n",
    "        \n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            nb_train = int(self.hparams.val_split * len(self.train_df))\n",
    "            # Split train df using fold\n",
    "            if self.hparams.val_fold is not None:\n",
    "                train_df = self.train_df[self.train_df.kfold != self.hparams.val_fold].reset_index(drop=True)\n",
    "                val_df = self.train_df[self.train_df.kfold == self.hparams.val_fold].reset_index(drop=True)\n",
    "            else:\n",
    "                train_df = self.train_df[:-nb_train].reset_index(drop=True)\n",
    "                val_df = self.train_df[-nb_train:].reset_index(drop=True)\n",
    "\n",
    "            self.train_dataset = TurtleDataset(train_df, trainFlag = True)\n",
    "            self.val_dataset = TurtleDataset(val_df, trainFlag = True)\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_dataset = TurtleDataset(self.test_df,trainFlag=False)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return self._dataloader(self.train_dataset, train=True)\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return self._dataloader(self.val_dataset)\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return self._dataloader(self.test_dataset)\n",
    "\n",
    "    def _dataloader(self, dataset: TurtleDataset, train: bool = False) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=train,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=train,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.251227Z",
     "iopub.status.busy": "2022-04-27T13:13:44.250902Z",
     "iopub.status.idle": "2022-04-27T13:13:44.267517Z",
     "shell.execute_reply": "2022-04-27T13:13:44.266742Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.251185Z"
    }
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    r\"\"\"Implement of large margin arc distance: :\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        s: norm of input feature\n",
    "        m: margin\n",
    "        cos(theta + m)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        s: float,\n",
    "        m: float,\n",
    "        easy_margin: bool,\n",
    "        ls_eps: float,\n",
    "    ):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input: torch.Tensor, label: torch.Tensor, device: str = \"cuda\") -> torch.Tensor:\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        # Enable 16 bit precision\n",
    "        cosine = cosine.to(torch.float32)\n",
    "\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device=device)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.269440Z",
     "iopub.status.busy": "2022-04-27T13:13:44.269035Z",
     "iopub.status.idle": "2022-04-27T13:13:44.281135Z",
     "shell.execute_reply": "2022-04-27T13:13:44.280277Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.269399Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/haqishen/Google-Landmark-Recognition-2020-3rd-Place-Solution/blob/main/landmark-recognition-2020-third-place-submission.ipynb\n",
    "class ArcMarginProduct_subcenter(nn.Module):\n",
    "    def __init__(self, in_features, out_features, k=3):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features*k, in_features))\n",
    "        self.reset_parameters()\n",
    "        self.k = k\n",
    "        self.out_features = out_features\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        cosine_all = F.linear(F.normalize(features), F.normalize(self.weight))\n",
    "        cosine_all = cosine_all.view(-1, self.out_features, self.k)\n",
    "        cosine, _ = torch.max(cosine_all, dim=2)\n",
    "        return cosine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:13:44.284960Z",
     "iopub.status.busy": "2022-04-27T13:13:44.284576Z",
     "iopub.status.idle": "2022-04-27T13:13:44.294905Z",
     "shell.execute_reply": "2022-04-27T13:13:44.294131Z",
     "shell.execute_reply.started": "2022-04-27T13:13:44.284913Z"
    }
   },
   "outputs": [],
   "source": [
    "class FocalCosineLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, xent=.1):\n",
    "        super(FocalCosineLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.xent = xent\n",
    "\n",
    "        self.y = torch.Tensor([1]).cuda()\n",
    "\n",
    "    def forward(self, input, target, reduction=\"mean\"):\n",
    "        cosine_loss = F.cosine_embedding_loss(input, F.one_hot(target, num_classes=input.size(-1)), self.y, reduction=reduction)\n",
    "\n",
    "        cent_loss = F.cross_entropy(F.normalize(input), target, reduce=False)\n",
    "        pt = torch.exp(-cent_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * cent_loss\n",
    "\n",
    "        if reduction == \"mean\":\n",
    "            focal_loss = torch.mean(focal_loss)\n",
    "\n",
    "        return cosine_loss + self.xent * focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:14:18.643999Z",
     "iopub.status.busy": "2022-04-27T13:14:18.643737Z",
     "iopub.status.idle": "2022-04-27T13:14:18.660456Z",
     "shell.execute_reply": "2022-04-27T13:14:18.659789Z",
     "shell.execute_reply.started": "2022-04-27T13:14:18.643969Z"
    }
   },
   "outputs": [],
   "source": [
    "class LitModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        pretrained: bool,\n",
    "        drop_rate: float,\n",
    "        embedding_size: int,\n",
    "        num_classes: int,\n",
    "        arc_s: float,\n",
    "        arc_m: float,\n",
    "        arc_easy_margin: bool,\n",
    "        arc_ls_eps: float,\n",
    "        optimizer: str,\n",
    "        learning_rate: float,\n",
    "        weight_decay: float,\n",
    "        len_train_dl: int,\n",
    "        batch_size: int,\n",
    "        epochs: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, drop_rate=drop_rate)\n",
    "        self.embedding = nn.Linear(self.model.classifier.in_features, embedding_size)\n",
    "        self.model.reset_classifier(num_classes=0, global_pool=\"avg\")\n",
    "\n",
    "        self.arc = ArcMarginProduct_subcenter(embedding_size, num_classes)\n",
    "        \n",
    "        self.arc_aux = ArcMarginProduct(\n",
    "            in_features=embedding_size,\n",
    "            out_features=4,\n",
    "            s=arc_s,\n",
    "            m=arc_m,\n",
    "            easy_margin=arc_easy_margin,\n",
    "            ls_eps=arc_ls_eps,\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(embedding_size, 4)\n",
    "\n",
    "        self.loss_fn2 = nn.CrossEntropyLoss(ignore_index=3) # do not compute loss for unknown image location 3 (\"unknown\")\n",
    "        self.loss_fn1 = FocalCosineLoss()\n",
    "\n",
    "    def forward(self, images: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.model(images)\n",
    "        embeddings = self.embedding(features)\n",
    "        return embeddings\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = create_optimizer_v2(\n",
    "            self.parameters(),\n",
    "            opt=self.hparams.optimizer,\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            self.hparams.learning_rate,\n",
    "            steps_per_epoch=self.hparams.len_train_dl,\n",
    "            epochs=self.hparams.epochs,\n",
    "        )\n",
    "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        return self._step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        return self._step(batch, \"val\")\n",
    "\n",
    "    def _step(self, batch: Dict[str, torch.Tensor], step: str) -> torch.Tensor:\n",
    "        images, targets , loc_targets = batch[\"image\"], batch[\"target\"], batch['loc_target']\n",
    "        \n",
    "        embeddings = self(images)\n",
    "        outputs = self.arc(embeddings)\n",
    "        \n",
    "        outputs2 = self.arc_aux(embeddings, loc_targets)\n",
    "        outputs3 = self.fc(embeddings)\n",
    "        \n",
    "        aux_outputs= 0.9*outputs2 + 0.1*outputs3 \n",
    "\n",
    "        loss1 = self.loss_fn1(outputs, targets)\n",
    "        loss2 = self.loss_fn2(aux_outputs, loc_targets)\n",
    "        \n",
    "        loss = 0.95*loss1 + 0.05*loss2\n",
    "        \n",
    "        self.log(f\"{step}_loss\", loss)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:14:22.363124Z",
     "iopub.status.busy": "2022-04-27T13:14:22.362558Z",
     "iopub.status.idle": "2022-04-27T13:14:22.378048Z",
     "shell.execute_reply": "2022-04-27T13:14:22.377095Z",
     "shell.execute_reply.started": "2022-04-27T13:14:22.363085Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import StochasticWeightAveraging\n",
    "\n",
    "\n",
    "def train(\n",
    "    train_csv_encoded_folded: str = './train_folds.csv',\n",
    "    test_csv: str = './test.csv',\n",
    "    val_fold: int = 0,\n",
    "    image_size: int = 256,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 4,\n",
    "    model_name: str = \"tf_efficientnet_b4\",\n",
    "    pretrained: bool = True,\n",
    "    drop_rate: float = 0.0,\n",
    "    embedding_size: int = 512,\n",
    "    arc_s: float = 30.0,\n",
    "    arc_m: float = 0.5,\n",
    "    arc_easy_margin: bool = False,\n",
    "    arc_ls_eps: float = 0.0,\n",
    "    optimizer: str = \"adamw\",\n",
    "    learning_rate: float = 3e-4,\n",
    "    weight_decay: float = 1e-6,\n",
    "    checkpoints_dir: str = '.',\n",
    "    accumulate_grad_batches: int = 1,\n",
    "    auto_scale_batch_size: bool = True,\n",
    "    gpus: int = 1,\n",
    "    max_epochs: int = 15,\n",
    "    precision: int = 16,\n",
    "):\n",
    "\n",
    "    datamodule = LitDataModule(\n",
    "        train_csv_encoded_folded=train_csv_encoded_folded,\n",
    "        test_csv=test_csv,\n",
    "        val_fold = val_fold,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    \n",
    "    datamodule.setup()\n",
    "    print(datamodule.num_classes)\n",
    "    len_train_dl = len(datamodule.train_dataloader())\n",
    "\n",
    "    model = LitModule(\n",
    "        model_name=model_name,\n",
    "        pretrained=pretrained,\n",
    "        drop_rate=drop_rate,\n",
    "        embedding_size=embedding_size,\n",
    "        num_classes=datamodule.num_classes,\n",
    "        arc_s=arc_s,\n",
    "        arc_m=arc_m,\n",
    "        arc_easy_margin=arc_easy_margin,\n",
    "        arc_ls_eps=arc_ls_eps,\n",
    "        optimizer=optimizer,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        len_train_dl=len_train_dl,\n",
    "        batch_size=batch_size,\n",
    "        epochs=max_epochs\n",
    "    )\n",
    "    \n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        checkpoints_dir,\n",
    "        filename=f\"{model_name}_{image_size}_{val_fold}\",\n",
    "        monitor=\"val_loss\",\n",
    "    )\n",
    "    \n",
    "    swa = StochasticWeightAveraging(swa_epoch_start=0.6)\n",
    "    logger = CSVLogger(save_dir='logs/')\n",
    "        \n",
    "    trainer = pl.Trainer(\n",
    "        accumulate_grad_batches=accumulate_grad_batches,\n",
    "        benchmark=True,\n",
    "        logger=logger,\n",
    "        callbacks=[model_checkpoint],\n",
    "        gpus=gpus,\n",
    "        max_epochs=max_epochs,\n",
    "        precision=precision,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    \n",
    "    return model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-27T13:14:56.325196Z",
     "iopub.status.busy": "2022-04-27T13:14:56.324653Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"tf_efficientnet_b5\"\n",
    "IMAGE_SIZE = 512\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "for fold in range(5):\n",
    "    model, trainer = train(model_name=MODEL_NAME,val_fold=fold, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n",
    "del metrics[\"step\"]\n",
    "metrics.set_index(\"epoch\", inplace=True)\n",
    "display(metrics.dropna(axis=1, how=\"all\").head())\n",
    "g = sn.relplot(data=metrics, kind=\"line\")\n",
    "plt.gcf().set_size_inches(12, 4)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eval_module(checkpoint_path: str, device: torch.device) -> LitModule:\n",
    "    module = LitModule.load_from_checkpoint(checkpoint_path)\n",
    "    module.to(device)\n",
    "    module.eval()\n",
    "\n",
    "    return module\n",
    "\n",
    "\n",
    "def load_encoder() -> LabelEncoder:\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.classes_ = np.load('./turtle_ids.npy', allow_pickle=True)\n",
    "\n",
    "    return encoder\n",
    "\n",
    "def create_and_search_index(embedding_size: int, train_embeddings: np.ndarray, val_embeddings: np.ndarray, k: int):\n",
    "    index = faiss.IndexFlatIP(embedding_size)\n",
    "    index.add(train_embeddings)\n",
    "    D, I = index.search(val_embeddings, k=k)  \n",
    "\n",
    "    return D, I\n",
    "\n",
    "\n",
    "def create_val_targets_df(\n",
    "    train_targets: np.ndarray, val_image_names: np.ndarray, val_targets: np.ndarray\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    allowed_targets = np.unique(train_targets)\n",
    "    val_targets_df = pd.DataFrame(np.stack([val_image_names, val_targets], axis=1), columns=[\"image\", \"target\"])\n",
    "    val_targets_df.loc[~val_targets_df.target.isin(allowed_targets), \"target\"] = \"new_turtle\"\n",
    "\n",
    "    return val_targets_df\n",
    "\n",
    "\n",
    "def create_distances_df(\n",
    "    image_names: np.ndarray, targets: np.ndarray, D: np.ndarray, I: np.ndarray, stage: str \n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    distances_df = []\n",
    "    for i, image_name in tqdm(enumerate(image_names), desc=f\"Creating {stage}_df\"):\n",
    "        target = targets[I[i]]\n",
    "        distances = D[i]\n",
    "        subset_preds = pd.DataFrame(np.stack([target, distances], axis=1), columns=[\"target\", \"distances\"])\n",
    "        subset_preds[\"image\"] = image_name\n",
    "        distances_df.append(subset_preds)\n",
    "\n",
    "    distances_df = pd.concat(distances_df).reset_index(drop=True)\n",
    "    distances_df = distances_df.groupby([\"image\", \"target\"]).distances.max().reset_index()\n",
    "    distances_df = distances_df.sort_values(\"distances\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return distances_df\n",
    "\n",
    "\n",
    "def get_best_threshold(val_targets_df: pd.DataFrame, valid_df: pd.DataFrame) -> Tuple[float, float]:\n",
    "    best_th = 0\n",
    "    best_cv = 0\n",
    "    for th in [0.1 * x for x in range(11)]:\n",
    "        all_preds = get_predictions(valid_df, threshold=th)\n",
    "\n",
    "        cv = 0\n",
    "        for i, row in val_targets_df.iterrows():\n",
    "            target = row.target\n",
    "            preds = all_preds[row.image]\n",
    "            val_targets_df.loc[i, th] = map_per_image(target, preds)\n",
    "\n",
    "        cv = val_targets_df[th].mean()\n",
    "\n",
    "        print(f\"th={th} cv={cv}\")\n",
    "\n",
    "        if cv > best_cv:\n",
    "            best_th = th\n",
    "            best_cv = cv\n",
    "\n",
    "    print(f\"best_th={best_th}\")\n",
    "    print(f\"best_cv={best_cv}\")\n",
    "\n",
    "    return best_th, best_cv\n",
    "\n",
    "\n",
    "def get_predictions(df: pd.DataFrame, threshold: float = 0.2):\n",
    "\n",
    "    predictions = {}\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=f\"Creating predictions for threshold={threshold}\"):\n",
    "        if row.image in predictions:\n",
    "            if len(predictions[row.image]) == 5:\n",
    "                continue\n",
    "            predictions[row.image].append(row.target)\n",
    "        elif row.distances > threshold:\n",
    "            predictions[row.image] = [row.target, \"new_turtle\"]\n",
    "        else:\n",
    "            predictions[row.image] = [\"new_turtle\", row.target]\n",
    "\n",
    "    for x in tqdm(predictions):\n",
    "        if len(predictions[x]) < 5:\n",
    "            predictions[x] = (predictions[x] + ['new_turtle']*5)[:5]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def map_per_image(label, predictions):\n",
    "    \"\"\"Computes the precision score of one image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label : string\n",
    "            The true label of the image\n",
    "    predictions : list\n",
    "            A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return 1 / (predictions[:5].index(label) + 1)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def create_predictions_df(test_df: pd.DataFrame, best_th: float) -> pd.DataFrame:\n",
    "    predictions = get_predictions(test_df, best_th)\n",
    "\n",
    "    predictions = pd.Series(predictions).reset_index()\n",
    "    predictions.columns = [\"image\", \"predictions\"]\n",
    "    predictions[\"predictions\"] = predictions[\"predictions\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataloaders(\n",
    "    train_csv_encoded_folded: str,\n",
    "    test_csv: str,\n",
    "    val_fold: float,\n",
    "    image_size: int,\n",
    "    batch_size: int,\n",
    "    num_workers: int,\n",
    ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "\n",
    "    datamodule = LitDataModule(\n",
    "        train_csv_encoded_folded=train_csv_encoded_folded,\n",
    "        test_csv=test_csv,\n",
    "        val_fold=val_fold,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    datamodule.setup()\n",
    "\n",
    "    train_dl = datamodule.train_dataloader()\n",
    "    val_dl = datamodule.val_dataloader()\n",
    "    test_dl = datamodule.test_dataloader()\n",
    "\n",
    "    return train_dl, val_dl, test_dl\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def get_embeddings(\n",
    "    module: pl.LightningModule, dataloader: DataLoader, encoder: LabelEncoder, stage: str\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "\n",
    "\n",
    "    if stage in ['train', 'val']:\n",
    "        \n",
    "        all_image_names = []\n",
    "        all_embeddings = []\n",
    "        all_targets = []\n",
    "    \n",
    "\n",
    "        for batch in tqdm(dataloader, desc=f\"Creating {stage} embeddings\"):\n",
    "\n",
    "            image_names = batch[\"image_name\"]\n",
    "            images = batch[\"image\"].to(module.device)\n",
    "            targets = batch[\"target\"].to(module.device)\n",
    "            loc_targets = batch[\"loc_target\"].to(module.device)\n",
    "\n",
    "            embeddings = module(images)\n",
    "\n",
    "            all_image_names.append(image_names)\n",
    "            all_embeddings.append(embeddings.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "        all_image_names = np.concatenate(all_image_names)\n",
    "        all_embeddings = np.vstack(all_embeddings)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "\n",
    "        all_embeddings = normalize(all_embeddings, axis=1, norm=\"l2\")\n",
    "        all_targets = encoder.inverse_transform(all_targets)\n",
    "\n",
    "        return all_image_names, all_embeddings, all_targets\n",
    "    \n",
    "    else:\n",
    "        all_image_names = []\n",
    "        all_embeddings = []\n",
    "        \n",
    "        for batch in tqdm(dataloader, desc=f\"Creating {stage} embeddings\"):\n",
    "\n",
    "            image_names = batch[\"image_name\"]\n",
    "            images = batch[\"image\"].to(module.device)\n",
    "\n",
    "            embeddings = module(images)\n",
    "\n",
    "            all_image_names.append(image_names)\n",
    "            all_embeddings.append(embeddings.cpu().numpy())\n",
    "\n",
    "        all_image_names = np.concatenate(all_image_names)\n",
    "        all_embeddings = np.vstack(all_embeddings)\n",
    "\n",
    "        all_embeddings = normalize(all_embeddings, axis=1, norm=\"l2\")\n",
    "\n",
    "        return all_image_names, all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def infer(\n",
    "    checkpoint_path: str,\n",
    "    train_csv_encoded_folded: str = './train_folds.csv',\n",
    "    test_csv: str = './test.csv',\n",
    "    val_fold: float = 0,\n",
    "    image_size: int = 256,\n",
    "    batch_size: int = 64,\n",
    "    num_workers: int = 2,\n",
    "    k: int = 50,\n",
    "):\n",
    "    module = load_eval_module(checkpoint_path, torch.device(\"cuda\"))\n",
    "\n",
    "    train_dl, val_dl, test_dl = load_dataloaders(\n",
    "        train_csv_encoded_folded=train_csv_encoded_folded,\n",
    "        test_csv=test_csv,\n",
    "        val_fold=val_fold,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    encoder = load_encoder()\n",
    "\n",
    "    train_image_names, train_embeddings, train_targets = get_embeddings(module, train_dl, encoder, stage=\"train\")\n",
    "    val_image_names, val_embeddings, val_targets = get_embeddings(module, val_dl, encoder, stage=\"val\")\n",
    "    test_image_names, test_embeddings = get_embeddings(module, test_dl, encoder, stage=\"test\")\n",
    "\n",
    "    D, I = create_and_search_index(module.hparams.embedding_size, train_embeddings, val_embeddings, k)\n",
    "    print(\"Created index with train_embeddings\")\n",
    "\n",
    "    val_targets_df = create_val_targets_df(train_targets, val_image_names, val_targets)\n",
    "    print(f\"val_targets_df=\\n{val_targets_df.head()}\")\n",
    "\n",
    "    val_df = create_distances_df(val_image_names, train_targets, D, I, \"val\")\n",
    "    print(f\"val_df=\\n{val_df.head()}\")\n",
    "\n",
    "    best_th, best_cv = get_best_threshold(val_targets_df, val_df)\n",
    "    print(f\"val_targets_df=\\n{val_targets_df.describe()}\")\n",
    "\n",
    "    train_embeddings = np.concatenate([train_embeddings, val_embeddings])\n",
    "    train_targets = np.concatenate([train_targets, val_targets])\n",
    "    print(\"Updated train_embeddings and train_targets with val data\")\n",
    "\n",
    "    D, I = create_and_search_index(module.hparams.embedding_size, train_embeddings, test_embeddings, k)  \n",
    "    print(\"Created index with train_embeddings\")\n",
    "\n",
    "    test_df = create_distances_df(test_image_names, train_targets, D, I, \"test\")\n",
    "    print(f\"test_df=\\n{test_df.head()}\")\n",
    "\n",
    "    predictions = create_predictions_df(test_df, best_th)\n",
    "    print(f\"predictions.head()={predictions.head()}\")\n",
    "\n",
    "    predictions.to_csv(f'./submission_{val_fold}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fld in range(5):\n",
    "    \n",
    "    infer(checkpoint_path=f\"./{MODEL_NAME}_{IMAGE_SIZE}_{fld}.ckpt\",\n",
    "          val_fold = fld, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_files = [\n",
    "                 './submission_0.csv',\n",
    "                 './submission_1.csv',\n",
    "                 './submission_2.csv',\n",
    "                 './submission_3.csv',\n",
    "                 './submission_4.csv',\n",
    "\n",
    "]\n",
    "\n",
    "# Weights of the individual subs\n",
    "# NB : Weights (best CV score per fold) are computed from get_best_threshold search\n",
    "# Check best cv scores from the get_best_threshold outputs and insert for each placeholder below\n",
    "\n",
    "sub_weight = [\n",
    "                best_fold_1_cv_score**2,\n",
    "                best_fold_2_cv_score**2,\n",
    "                best_fold_3_cv_score**2,\n",
    "                best_fold_4_cv_score**2,\n",
    "                best_fold_5_cv_score**2\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hlabel = 'image' \n",
    "Htarget = 'predictions'\n",
    "npt = 5\n",
    "place_weights = {}\n",
    "for i in range(npt):\n",
    "    place_weights[i] = ( 1 / (i + 1) )\n",
    "    \n",
    "print(place_weights)\n",
    "\n",
    "lg = len(sub_files)\n",
    "sub = [None]*lg\n",
    "for i, file in enumerate( sub_files ):\n",
    "   \n",
    "    print(\"Reading {}: w={} - {}\". format(i, sub_weight[i], file))\n",
    "    reader = csv.DictReader(open(file,\"r\"))\n",
    "    sub[i] = sorted(reader, key=lambda d: str(d[Hlabel]))\n",
    "\n",
    "out = open(\"sub_ens.csv\", \"w\", newline='')\n",
    "writer = csv.writer(out)\n",
    "writer.writerow([Hlabel,Htarget])\n",
    "\n",
    "for p, row in enumerate(sub[0]):\n",
    "    target_weight = {}\n",
    "    for s in range(lg):\n",
    "        row1 = sub[s][p]\n",
    "        for ind, trgt in enumerate(row1[Htarget].split(' ')):\n",
    "            target_weight[trgt] = target_weight.get(trgt,0) + (place_weights[ind]*sub_weight[s])\n",
    "    tops_trgt = sorted(target_weight, key=target_weight.get, reverse=True)[:npt]\n",
    "    writer.writerow([row1[Hlabel], \" \".join(tops_trgt)])\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('./sub_ens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = result.predictions.apply(lambda x : x.split(\" \")).values.tolist()\n",
    "result_df = pd.DataFrame(pred_list, columns=['prediction1', 'prediction2', 'prediction3', 'prediction4', 'prediction5'])\n",
    "result_df['image_id'] = result['image'].copy()\n",
    "\n",
    "result_df['image_id'] = result_df['image_id'].apply(lambda x : x.replace('.png', ''))\n",
    "result_df = result_df[['image_id','prediction1', 'prediction2','prediction3','prediction4','prediction5']].copy()\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./submission.csv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
