{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eX5VkLN0tzXY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eX5VkLN0tzXY",
    "outputId": "402e023b-f260-4466-f743-2528f2b299a1"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/adnan119/TRACER.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z7oCiQ0PtzSg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7oCiQ0PtzSg",
    "outputId": "462a23bf-7f07-4e13-e64c-98cef245e9e4"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/Karel911/TRACER/releases/download/v1.0/TRACER-Efficient-7.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Tb1SHT4mtzJO",
   "metadata": {
    "id": "Tb1SHT4mtzJO"
   },
   "outputs": [],
   "source": [
    "!mv ./TRACER-Efficient-7.pth ./best_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debf0186",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "debf0186",
    "outputId": "5ae55dbd-8185-4aeb-a224-710db427662a"
   },
   "outputs": [],
   "source": [
    "!pip install timm faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gqpE93Rxmw_W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqpE93Rxmw_W",
    "outputId": "77d763a0-4e01-4352-cb7b-4c7436d68168"
   },
   "outputs": [],
   "source": [
    "!pip install fastai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pSVrIaYF7nP-",
   "metadata": {
    "id": "pSVrIaYF7nP-"
   },
   "outputs": [],
   "source": [
    "!pip uninstall torch -y\n",
    "# CUDA 10.1\n",
    "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install fastai==2.0.19\n",
    "!pip install fastcore==1.3.1 \n",
    "!pip install wwf -q --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xQx-TMm-uGJJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQx-TMm-uGJJ",
    "outputId": "e5e954ca-e4ca-4d52-8610-abce8687c6fb"
   },
   "outputs": [],
   "source": [
    "%cd ./TRACER\n",
    "!mkdir ./results/\n",
    "!mkdir ./results/DUTS/\n",
    "!mkdir ./results/DUTS/TE7_0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eenzoybWuKrV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eenzoybWuKrV",
    "outputId": "6d5f3111-7ce9-4716-cd60-f2ce49381286"
   },
   "outputs": [],
   "source": [
    "!mv ../best_model.pth ./results/DUTS/TE7_0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lkPJpUDL4ZzT",
   "metadata": {
    "id": "lkPJpUDL4ZzT"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB : Restart notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de59e3",
   "metadata": {
    "id": "33de59e3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.learner import _update_first_layer\n",
    "import faiss\n",
    "from timm import create_model\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dHORnGuKnN",
   "metadata": {
    "id": "c7dHORnGuKnN"
   },
   "outputs": [],
   "source": [
    "# segment all images to remove background\n",
    "!python main.py test --exp_num 0 --arch 7 --img_size 640 --batch_size 16 --dataset \"DUTS\" --save_map True --data_path /path/to/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DvgfeIJLuKjt",
   "metadata": {
    "id": "DvgfeIJLuKjt"
   },
   "outputs": [],
   "source": [
    "!ls seg_img | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N3LA8POgQ_JQ",
   "metadata": {
    "id": "N3LA8POgQ_JQ"
   },
   "outputs": [],
   "source": [
    "shutil.make_archive('./seg_img', 'zip', './seg_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94X93mdtXP2D",
   "metadata": {
    "id": "94X93mdtXP2D"
   },
   "outputs": [],
   "source": [
    "!mv ./TRACER/seg_img.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P9VEhbSkXfkH",
   "metadata": {
    "id": "P9VEhbSkXfkH"
   },
   "outputs": [],
   "source": [
    "!rm -r seg_img\n",
    "!rm seg_img.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seMrdMcWlnqo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seMrdMcWlnqo",
    "outputId": "9e0e7c8a-65df-4091-e69e-b74be7827c40"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YmNzedK3bL0r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmNzedK3bL0r",
    "outputId": "f707dedf-0d85-4336-a83f-3f9670e8bb03"
   },
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g9v0zY11pRrW",
   "metadata": {
    "id": "g9v0zY11pRrW"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XKK1KCm0bfHe",
   "metadata": {
    "id": "XKK1KCm0bfHe"
   },
   "outputs": [],
   "source": [
    "!rm -r TRACER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sI3XPyOsZ3Ko",
   "metadata": {
    "id": "sI3XPyOsZ3Ko"
   },
   "outputs": [],
   "source": [
    "!unzip seg_img.zip -d clean_turtle_background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hydg4HKVcPtO",
   "metadata": {
    "id": "Hydg4HKVcPtO"
   },
   "outputs": [],
   "source": [
    "!rm seg_img.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O18PaOeAm_HV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O18PaOeAm_HV",
    "outputId": "361c496a-d8d0-4c31-d66e-007dca7ad47a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "SOURCE_URL = 'https://storage.googleapis.com/dm-turtle-recall/images.tar'\n",
    "IMAGE_DIR = './turtle_recall/images'\n",
    "TAR_PATH = os.path.join(IMAGE_DIR, os.path.basename(SOURCE_URL))\n",
    "EXPECTED_IMAGE_COUNT = 13891\n",
    "\n",
    "%sx mkdir --parents \"{IMAGE_DIR}\"\n",
    "if len(os.listdir(IMAGE_DIR)) != EXPECTED_IMAGE_COUNT:\n",
    "  %sx wget --no-check-certificate -O \"{TAR_PATH}\" \"{SOURCE_URL}\"\n",
    "  %sx tar --extract --file=\"{TAR_PATH}\" --directory=\"{IMAGE_DIR}\"\n",
    "  %sx rm \"{TAR_PATH}\"\n",
    "\n",
    "print(f'The total number of images is: {len(os.listdir(IMAGE_DIR))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e4caf",
   "metadata": {
    "id": "961e4caf"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path(\".\")\n",
    "DATA_ROOT_DIR = Path(\"/content/turtle_recall/images\")\n",
    "SUBMISSION_CSV_PATH = OUTPUT_DIR / \"submission.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c97aec",
   "metadata": {
    "id": "e4c97aec"
   },
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wb3WHGWXnpw0",
   "metadata": {
    "id": "Wb3WHGWXnpw0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import urllib.parse\n",
    "\n",
    "BASE_URL = 'https://storage.googleapis.com/dm-turtle-recall/'\n",
    "\n",
    "\n",
    "def read_csv_from_web(file_name):\n",
    "  url = urllib.parse.urljoin(BASE_URL, file_name)\n",
    "  content = requests.get(url).content\n",
    "  return pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
    "\n",
    "\n",
    "# Read in csv files.\n",
    "train = read_csv_from_web('train.csv')\n",
    "extra_train = read_csv_from_web('extra_images.csv')\n",
    "test_df = read_csv_from_web('test.csv')\n",
    "sample_submission = read_csv_from_web('sample_submission.csv')\n",
    "\n",
    "# Convert image_location strings to lowercase.\n",
    "for df in [train, test_df]:\n",
    "  df.image_location = df.image_location.apply(lambda x: x.lower())\n",
    "  assert set(df.image_location.unique()) == set(['left', 'right', 'top'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prKOCgvSnt6Y",
   "metadata": {
    "id": "prKOCgvSnt6Y"
   },
   "outputs": [],
   "source": [
    "classes = list(train.turtle_id.unique()) + list(extra_train.turtle_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0uIimn-Ko1vA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0uIimn-Ko1vA",
    "outputId": "e161e10d-2982-4cf2-df51-5e1814e20e19"
   },
   "outputs": [],
   "source": [
    "classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RyI17cRwOVBX",
   "metadata": {
    "id": "RyI17cRwOVBX"
   },
   "outputs": [],
   "source": [
    "new_data = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qtXIzmV4H4WP",
   "metadata": {
    "id": "qtXIzmV4H4WP"
   },
   "outputs": [],
   "source": [
    "new_data['image_id'] = new_data['image_id'] + '.png'\n",
    "new_data['image_path'] = new_data['image_id'].apply(lambda x : f'/content/clean_turtle_background/{str(x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087d39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_1 = extra_train.copy()\n",
    "extra_1['image_id'] = extra_1['image_id'] + '.JPG'\n",
    "extra_1['image_path'] = extra_1['image_id'].apply(lambda x : DATA_ROOT_DIR / str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f4773",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_2 = extra_train.copy()\n",
    "extra_2['image_id'] = extra_2['image_id'] + '.png'\n",
    "extra_2['image_path'] = extra_2['image_id'].apply(lambda x : f'/content/clean_turtle_background/{str(x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6189266",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_train = pd.concat([extra_1, extra_2], \n",
    "                        axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del extra_1, extra_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kHawoBmaOq-8",
   "metadata": {
    "id": "kHawoBmaOq-8"
   },
   "outputs": [],
   "source": [
    "train['image_id']   = train['image_id'] + '.JPG'\n",
    "test_df['image_id'] = test_df['image_id'] + '.JPG'\n",
    "\n",
    "train['image_path']   = train['image_id'].apply(lambda x : DATA_ROOT_DIR / str(x))\n",
    "test_df['image_path'] = test_df['image_id'].apply(lambda x : DATA_ROOT_DIR / str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c32234",
   "metadata": {
    "id": "e9c32234"
   },
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ls6ebGfC2fj-",
   "metadata": {
    "id": "Ls6ebGfC2fj-"
   },
   "outputs": [],
   "source": [
    "augmented_train = pd.concat([train, new_data], axis=0, ignore_index=True)\n",
    "folds = pd.concat([augmented_train, extra_train], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e3375",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fb6e3375",
    "outputId": "a4f2f7e5-79ec-4ce4-b3c1-d53e27ed9f74"
   },
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(folds['turtle_id'])\n",
    "np.save('turtle_ids.npy', encoder.classes_)\n",
    "\n",
    "\n",
    "folds[\"label\"] = encoder.transform(folds['turtle_id'])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "for fold, (_, val_) in enumerate(skf.split(X=folds, y=folds.turtle_id)):\n",
    "    folds.loc[val_, \"kfold\"] = int(fold)\n",
    "    \n",
    "folds.drop('label',axis=1,inplace=True)\n",
    "folds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1de407",
   "metadata": {
    "id": "2c1de407"
   },
   "outputs": [],
   "source": [
    "folds['kfold'] = folds['kfold'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GH7BoTrLpv2y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "GH7BoTrLpv2y",
    "outputId": "c9962dc3-7bad-41dd-960b-f7117b7beebb"
   },
   "outputs": [],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f053efd3",
   "metadata": {
    "id": "f053efd3"
   },
   "outputs": [],
   "source": [
    "seed=42\n",
    "set_seed(seed, reproducible=True)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5bcbad",
   "metadata": {
    "id": "6b5bcbad"
   },
   "source": [
    "# Creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae873768",
   "metadata": {
    "id": "ae873768"
   },
   "outputs": [],
   "source": [
    "Val_Fold = 0\n",
    "\n",
    "def get_x(r): return r['image_path']\n",
    "def get_y(r): return [r['turtle_id']]\n",
    "\n",
    "def splitter(df): \n",
    "\n",
    "    train_ = df.index[df.kfold != Val_Fold].tolist()\n",
    "\n",
    "    valid_ = df.index[df.kfold == Val_Fold].tolist()\n",
    "\n",
    "    return [train_,valid_]\n",
    "\n",
    "def create_dls(df=folds, bs=8,Val_Fold=0,Image_size=512):\n",
    "    dblock = DataBlock(blocks = (ImageBlock,MultiCategoryBlock(vocab=classes)),\n",
    "                       get_x = get_x,\n",
    "                       get_y = get_y ,\n",
    "                       splitter = splitter,\n",
    "                       item_tfms = [Resize(1024)], \n",
    "                       batch_tfms =[*aug_transforms(size=Image_size, \n",
    "                                                    do_flip=True, flip_vert=True, max_rotate=5.0, \n",
    "                                                    p_affine=0.5, p_lighting=0.5, max_zoom=1.08,\n",
    "                                                    max_lighting=0.2, max_warp=0.2\n",
    "                                                    ),\n",
    "                                     Normalize.from_stats(*imagenet_stats)]\n",
    "                      )\n",
    "\n",
    "    dls = dblock.dataloaders(folds,bs=bs)\n",
    "\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5f81c",
   "metadata": {
    "id": "86f5f81c"
   },
   "outputs": [],
   "source": [
    "dls = create_dls(df=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a97130c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "6a97130c",
    "outputId": "f454ba85-c85f-402e-cad7-2030aa76d9d9"
   },
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23adb8d2",
   "metadata": {
    "id": "23adb8d2"
   },
   "outputs": [],
   "source": [
    "target_map = {N:CLASS for N,CLASS in enumerate(dls.vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c375c4",
   "metadata": {
    "id": "d9c375c4"
   },
   "source": [
    "# Arc Face loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba681d",
   "metadata": {
    "id": "cfba681d"
   },
   "outputs": [],
   "source": [
    "# From https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/blob/master/src/modeling/metric_learning.py\n",
    "# Added type annotations, device, and 16bit support\n",
    "class ArcMarginLoss(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        s: float,\n",
    "        m: float,\n",
    "        easy_margin: bool,\n",
    "        ls_eps: float,\n",
    "    ):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, logits, targ):\n",
    "        cosine = F.linear(F.normalize(logits), F.normalize(self.weight))\n",
    "        # Enable 16 bit precision\n",
    "        cosine = cosine.to(torch.float32)\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        if self.ls_eps > 0:\n",
    "            targ = (1 - self.ls_eps) * targ + self.ls_eps / self.out_features\n",
    "        output = (targ * phi) + ((1.0 - targ) * cosine)\n",
    "        output *= self.s\n",
    "        loss =  F.cross_entropy(output, torch.argmax(targ, dim=1))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1gxi5CPqXm8",
   "metadata": {
    "id": "u1gxi5CPqXm8"
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, \n",
    "                 m=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        '''\n",
    "        in_features: dimension of the input\n",
    "        out_features: dimension of the last layer (in our case the classification)\n",
    "        s: norm of input feature\n",
    "        m: margin\n",
    "        ls_eps: label smoothing'''\n",
    "        \n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features, self.out_features = in_features, out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        # Fills the input `Tensor` with values according to the method described in\n",
    "        # `Understanding the difficulty of training deep feedforward neural networks`\n",
    "        # Glorot, X. & Bengio, Y. (2010)\n",
    "        # using a uniform distribution.\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m, self.sin_m = math.cos(m), math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------\n",
    "        one_hot = torch.zeros(cosine.size()).to('cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TiU5e38uIqj8",
   "metadata": {
    "id": "TiU5e38uIqj8"
   },
   "outputs": [],
   "source": [
    "# https://github.com/haqishen/Google-Landmark-Recognition-2020-3rd-Place-Solution/blob/main/landmark-recognition-2020-third-place-submission.ipynb\n",
    "import math\n",
    "\n",
    "class ArcMarginProduct_subcenter(nn.Module):\n",
    "    def __init__(self, in_features, out_features, k=3):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features*k, in_features))\n",
    "        self.reset_parameters()\n",
    "        self.k = k\n",
    "        self.out_features = out_features\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        cosine_all = F.linear(F.normalize(features), F.normalize(self.weight))\n",
    "        cosine_all = cosine_all.view(-1, self.out_features, self.k)\n",
    "        cosine, _ = torch.max(cosine_all, dim=2)\n",
    "        \n",
    "        return cosine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fM3pUSrTEZwl",
   "metadata": {
    "id": "fM3pUSrTEZwl"
   },
   "outputs": [],
   "source": [
    "# src: https://amaarora.github.io/2020/08/30/gempool.html\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        # Applies 2D average-pooling operation in kH * kW regions by step size\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcca16a",
   "metadata": {
    "id": "ffcca16a"
   },
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a2955",
   "metadata": {
    "id": "734a2955"
   },
   "outputs": [],
   "source": [
    "def create_timm_body(arch:str, pretrained=True, drop_rate=0.0, cut=None, n_in=3):\n",
    "    \"Creates a body from any model in the `timm` library.\"\n",
    "    model = create_model(arch, pretrained=pretrained, drop_rate=drop_rate, \n",
    "                         num_classes=0, global_pool='')\n",
    "    _update_first_layer(model, n_in, pretrained)\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n",
    "    if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut): return cut(model)\n",
    "    else: raise NamedError(\"cut must be either integer or function\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6520a6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6520a6f",
    "outputId": "5d584907-b6d7-440e-9b89-ce726a568638"
   },
   "outputs": [],
   "source": [
    "emb_size = 2048 # 2048 used b5_ns\n",
    "body = create_timm_body('tf_efficientnet_b5_ns', pretrained=True)\n",
    "nf = num_features_model(nn.Sequential(*body.children()))\n",
    "head = nn.Sequential(GeM(),nn.Flatten(),\n",
    "                     nn.Linear(nf,emb_size,bias=False))\n",
    "\n",
    "model = nn.Sequential(body, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89861e70",
   "metadata": {
    "id": "89861e70"
   },
   "outputs": [],
   "source": [
    "loss_func = ArcMarginLoss(in_features=emb_size, out_features=dls.c,s=30.0,\n",
    "                          m = 0.3, easy_margin=False, ls_eps=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b4cd2",
   "metadata": {
    "id": "693b4cd2"
   },
   "outputs": [],
   "source": [
    "dls = create_dls(df=folds, bs=4,Image_size=512)\n",
    "learn = Learner(dls, model, \n",
    "                loss_func=loss_func, \n",
    "                splitter=default_split\n",
    "                ).to_fp16()\n",
    "learn.freeze()\n",
    "\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9f70e",
   "metadata": {
    "id": "4ec9f70e"
   },
   "outputs": [],
   "source": [
    "learn.lr_find() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5352b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "cce5352b",
    "outputId": "872f5e22-3a68-4e4e-86e3-7fe2e3b415ac"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1,lr_max=5e-4, wd = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0259b",
   "metadata": {
    "id": "d5a0259b"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(9,lr_max=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41e08a",
   "metadata": {
    "id": "7c41e08a"
   },
   "outputs": [],
   "source": [
    "learn.export('effnet_b5_ns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c817e923",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c817e923",
    "outputId": "c7b4b5bc-c09d-4c30-d15a-889ff8b51c96"
   },
   "outputs": [],
   "source": [
    "del learn\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf028d",
   "metadata": {
    "id": "7cdf028d"
   },
   "outputs": [],
   "source": [
    "def load_eval_learner(learner_path,output_group,dls,device):\n",
    "    learn = load_learner(learner_path)\n",
    "    learn.model.to(device)\n",
    "    learn.dls = dls\n",
    "    hook = Hook(learn.model[output_group], lambda m,i,o: o)\n",
    "    return learn, hook\n",
    "\n",
    "def load_dataloaders(train_df,test_df,val_fold):\n",
    "\n",
    "    dls = create_dls(df=train_df, Image_size=512, bs=8, Val_Fold=val_fold) \n",
    "\n",
    "    train_dataloader = dls.test_dl(train_df[train_df.kfold != val_fold],with_labels=True)\n",
    "    valid_dataloader = dls.test_dl(train_df[train_df.kfold == val_fold],with_labels=True)\n",
    "    test_dataloader  = dls.test_dl(test_df)\n",
    "    return train_dataloader, valid_dataloader, test_dataloader, dls\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_embeddings(module, dataloader, device, train=True):\n",
    "\n",
    "    all_image_names = []\n",
    "    all_embeddings = []\n",
    "    all_targets = []\n",
    "\n",
    "    if train:\n",
    "        \n",
    "        for (x, y) in tqdm(dataloader):\n",
    "            images =  x.to(device)\n",
    "            targets = y.to(device)\n",
    "            embeddings = module.model(images)\n",
    "            all_embeddings.append(embeddings.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "\n",
    "        all_image_names = dataloader.items['image_id'].values\n",
    "        all_embeddings = np.vstack(all_embeddings)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        all_targets = L(list(np.argmax(all_targets,axis=1)))\n",
    "        all_embeddings = normalize(all_embeddings, axis=1, norm=\"l2\")\n",
    "        all_targets = np.array(all_targets.map(target_map.__getitem__))\n",
    "      \n",
    "        return all_image_names, all_embeddings, all_targets\n",
    "    else:\n",
    "        for (x,) in tqdm(dataloader):\n",
    "            images =  x.to(device)\n",
    "            embeddings = module.model(images)\n",
    "            all_embeddings.append(embeddings.cpu().numpy())\n",
    "\n",
    "        all_image_names = dataloader.items['image_id'].values\n",
    "        all_embeddings = np.vstack(all_embeddings)\n",
    "        all_embeddings = normalize(all_embeddings, axis=1, norm=\"l2\")\n",
    "\n",
    "        return all_image_names, all_embeddings\n",
    "\n",
    "\n",
    "def create_and_search_index(embedding_size: int, train_embeddings: np.ndarray, val_embeddings: np.ndarray, k: int):\n",
    "    index = faiss.IndexFlatIP(embedding_size)\n",
    "    index.add(train_embeddings)\n",
    "    D, I = index.search(val_embeddings, k=k)  \n",
    "\n",
    "    return D, I\n",
    "\n",
    "def create_val_targets_df(\n",
    "    train_targets: np.ndarray, val_image_names: np.ndarray, val_targets: np.ndarray\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    allowed_targets = classes\n",
    "    val_targets_df = pd.DataFrame(np.stack([val_image_names, val_targets], axis=1), columns=[\"image\", \"target\"])\n",
    "    val_targets_df.loc[~val_targets_df.target.isin(allowed_targets), \"target\"] = \"new_turtle\"\n",
    "\n",
    "    return val_targets_df\n",
    "\n",
    "def create_distances_df(\n",
    "    image_names: np.ndarray, targets: np.ndarray, D: np.ndarray, I: np.ndarray, stage: str \n",
    ") -> pd.DataFrame:\n",
    "    distances_df = []\n",
    "    for i, image_name in tqdm(enumerate(image_names), desc=f\"Creating {stage}_df\"):\n",
    "        target = targets[I[i]]\n",
    "        distances = D[i]\n",
    "        subset_preds = pd.DataFrame(np.stack([target, distances], axis=1), columns=[\"target\", \"distances\"])\n",
    "        subset_preds[\"image\"] = image_name\n",
    "        distances_df.append(subset_preds)\n",
    "    distances_df = pd.concat(distances_df).reset_index(drop=True)\n",
    "    distances_df = distances_df.groupby([\"image\", \"target\"]).distances.max().reset_index()\n",
    "    distances_df = distances_df.sort_values(\"distances\", ascending=False).reset_index(drop=True)\n",
    "    return distances_df\n",
    "\n",
    "def get_best_threshold(val_targets_df: pd.DataFrame, valid_df: pd.DataFrame):\n",
    "    best_th = 0\n",
    "    best_cv = 0\n",
    "    for th in [0.1 * x for x in range(11)]:\n",
    "        all_preds = get_predictions(valid_df, threshold=th)\n",
    "\n",
    "        cv = 0\n",
    "        for i, row in val_targets_df.iterrows():\n",
    "            target = row.target\n",
    "            preds = all_preds[row.image]\n",
    "            val_targets_df.loc[i, th] = map_per_image(target, preds)\n",
    "\n",
    "        cv = val_targets_df[th].mean()\n",
    "\n",
    "        print(f\"th={th} cv={cv}\")\n",
    "\n",
    "        if cv > best_cv:\n",
    "            best_th = th\n",
    "            best_cv = cv\n",
    "\n",
    "    print(f\"best_th={best_th}\")\n",
    "    print(f\"best_cv={best_cv}\")\n",
    "\n",
    "    return best_th, best_cv\n",
    "\n",
    "def get_predictions(df: pd.DataFrame, threshold: float = 0.2):\n",
    "\n",
    "    predictions = {}\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=f\"Creating predictions for threshold={threshold}\"):\n",
    "        if row.image in predictions:\n",
    "            if len(predictions[row.image]) == 5:\n",
    "                continue\n",
    "            predictions[row.image].append(row.target)\n",
    "        elif float(row.distances) > threshold:\n",
    "            predictions[row.image] = [row.target, \"new_turtle\"]\n",
    "        else:\n",
    "            predictions[row.image] = [\"new_turtle\", row.target]\n",
    "\n",
    "    for x in tqdm(predictions):\n",
    "        if len(predictions[x]) < 5:\n",
    "            predictions[x] = (predictions[x] + ['new_turtle']*5)[:5]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def map_per_image(label, predictions):\n",
    "    \"\"\"Computes the precision score of one image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label : string\n",
    "            The true label of the image\n",
    "    predictions : list\n",
    "            A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return 1 / (predictions[:5].index(label) + 1)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def create_predictions_df(test_df: pd.DataFrame, best_th: float) -> pd.DataFrame:\n",
    "    predictions = get_predictions(test_df, best_th)\n",
    "\n",
    "    predictions = pd.Series(predictions).reset_index()\n",
    "    predictions.columns = [\"image\", \"predictions\"]\n",
    "    predictions[\"predictions\"] = predictions[\"predictions\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29afe7f0",
   "metadata": {
    "id": "29afe7f0"
   },
   "outputs": [],
   "source": [
    "def infer(\n",
    "    model_path: str,\n",
    "    train_df: pd.DataFrame = folds,\n",
    "    test_df: pd.DataFrame = test_df,\n",
    "    val_fold: float = 0,\n",
    "    k: int = 50,\n",
    "    emb_size:int = emb_size\n",
    "):\n",
    "    train_dl, val_dl, test_dl,dls = load_dataloaders(folds,test_df,val_fold)\n",
    "    (learn, hook) = load_eval_learner(model_path,1,dls,torch.device(\"cuda\"))\n",
    "\n",
    "    train_image_names, train_embeddings, train_targets = get_embeddings(learn, train_dl,torch.device(\"cuda\"))\n",
    "    val_image_names, val_embeddings, val_targets = get_embeddings(learn, val_dl,torch.device(\"cuda\"))\n",
    "    test_image_names, test_embeddings = get_embeddings(learn, test_dl,torch.device(\"cuda\"),train=False)\n",
    "\n",
    "    D, I = create_and_search_index(emb_size, train_embeddings, val_embeddings, k) \n",
    "    print(\"Created index with train_embeddings\")\n",
    "    \n",
    "    val_targets_df = create_val_targets_df(train_targets, val_image_names, val_targets)\n",
    "    print(f\"val_targets_df=\\n{val_targets_df.head()}\")\n",
    "    print(f\"val_targets_df shape=\\n{val_targets_df.shape}\")\n",
    "    val_df = create_distances_df(val_image_names, train_targets, D, I, \"val\")\n",
    "    print(f\"val_df=\\n{val_df.head()}\")\n",
    "    print(f\"val_df shape=\\n{val_df.shape}\")\n",
    "    best_th, best_cv = get_best_threshold(val_targets_df, val_df)\n",
    "    print(f\"val_targets_df=\\n{val_targets_df.describe()}\")\n",
    "    print(f\"val_targets_df shape=\\n{val_targets_df.shape}\")\n",
    "    train_embeddings = np.concatenate([train_embeddings, val_embeddings])\n",
    "    train_targets = np.concatenate([train_targets, val_targets])\n",
    "    print(\"Updated train_embeddings and train_targets with val data\")\n",
    "\n",
    "    D, I = create_and_search_index(emb_size, train_embeddings, test_embeddings, k) \n",
    "    print(\"Created index with train_embeddings\")\n",
    "\n",
    "    test_df = create_distances_df(test_image_names, train_targets, D, I, \"test\")\n",
    "    print(f\"test_df=\\n{test_df.head()}\")\n",
    "    print(f\"test_df shape=\\n{test_df.shape}\")\n",
    "\n",
    "    predictions = create_predictions_df(test_df, best_th)\n",
    "    print(f\"predictions.head()={predictions.head()}\")\n",
    "    print(f\"predictions shape={predictions.shape}\")\n",
    "\n",
    "    predictions.to_csv(f'submission_{val_fold}.csv', index=False)\n",
    "\n",
    "    print(f'Fold {val_fold} done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44147ccf",
   "metadata": {
    "id": "44147ccf"
   },
   "outputs": [],
   "source": [
    "for fold_num in range(5):\n",
    "  \n",
    "  infer(train_df = folds, test_df = test_df, model_path=\"effnet_b5_ns.pkl\", val_fold=fold_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W1BZSCRkkrIo",
   "metadata": {
    "id": "W1BZSCRkkrIo"
   },
   "outputs": [],
   "source": [
    "sub_files = [\n",
    "                 './submission_0.csv',\n",
    "                 './submission_1.csv',\n",
    "                 './submission_2.csv',\n",
    "                 './submission_3.csv',\n",
    "                 './submission_4.csv',\n",
    "\n",
    "]\n",
    "\n",
    "# Weights of the individual subs\n",
    "# NB : Weights (best CV score per fold) are computed from get_best_threshold search\n",
    "# Check best cv scores from the get_best_threshold outputs and insert for each placeholder below\n",
    "\n",
    "sub_weight = [\n",
    "                best_fold_1_cv_score**2,\n",
    "                best_fold_2_cv_score**2,\n",
    "                best_fold_3_cv_score**2,\n",
    "                best_fold_4_cv_score**2,\n",
    "                best_fold_5_cv_score**2\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xItPKZoWkpF6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xItPKZoWkpF6",
    "outputId": "e46f0a71-4f78-4594-99c0-539d093bd9ac"
   },
   "outputs": [],
   "source": [
    "Hlabel = 'image' \n",
    "Htarget = 'predictions'\n",
    "npt = 5\n",
    "place_weights = {}\n",
    "for i in range(npt):\n",
    "    place_weights[i] = ( 1 / (i + 1) )\n",
    "    \n",
    "print(place_weights)\n",
    "\n",
    "lg = len(sub_files)\n",
    "sub = [None]*lg\n",
    "for i, file in enumerate( sub_files ):\n",
    "   \n",
    "    print(\"Reading {}: w={} - {}\". format(i, sub_weight[i], file))\n",
    "    reader = csv.DictReader(open(file,\"r\"))\n",
    "    sub[i] = sorted(reader, key=lambda d: str(d[Hlabel]))\n",
    "\n",
    "out = open(\"sub_ens.csv\", \"w\", newline='')\n",
    "writer = csv.writer(out)\n",
    "writer.writerow([Hlabel,Htarget])\n",
    "\n",
    "for p, row in enumerate(sub[0]):\n",
    "    target_weight = {}\n",
    "    for s in range(lg):\n",
    "        row1 = sub[s][p]\n",
    "        for ind, trgt in enumerate(row1[Htarget].split(' ')):\n",
    "            target_weight[trgt] = target_weight.get(trgt,0) + (place_weights[ind]*sub_weight[s])\n",
    "    tops_trgt = sorted(target_weight, key=target_weight.get, reverse=True)[:npt]\n",
    "    writer.writerow([row1[Hlabel], \" \".join(tops_trgt)])\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rFvhCXQvqvn-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "rFvhCXQvqvn-",
    "outputId": "caf41413-ccc2-404d-859a-31c0048c186e"
   },
   "outputs": [],
   "source": [
    "result = pd.read_csv('/content/sub_ens.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f727a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = result.predictions.apply(lambda x : x.split(\" \")).values.tolist()\n",
    "result_df = pd.DataFrame(pred_list, columns=['prediction1', 'prediction2', 'prediction3', 'prediction4', 'prediction5'])\n",
    "result_df['image_id'] = result['image'].copy()\n",
    "\n",
    "result_df['image_id'] = result_df['image_id'].apply(lambda x : x.replace('.png', ''))\n",
    "result_df = result_df[['image_id','prediction1', 'prediction2','prediction3','prediction4','prediction5']].copy()\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./submission_b5_ns_fastai.csv.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fastai-baseline-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14970.347666,
   "end_time": "2022-03-29T19:44:50.044679",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-29T15:35:19.697013",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
